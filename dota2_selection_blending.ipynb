{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>DOTA2 winner</center></h1>\n",
    "    \n",
    "[Ссылка на соревнование](https://www.kaggle.com/c/mlcourse-dota2-win-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, TimeSeriesSplit,\\\n",
    "                                    cross_val_score, cross_validate\n",
    "import scipy.stats as stats\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import category_encoders as ce\n",
    "from tqdm import tqdm_notebook\n",
    "import json\n",
    "from itertools import combinations, groupby\n",
    "from functools import reduce\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "from itertools import groupby\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_selection import RFECV\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import KFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для чтения json файлов\n",
    "def read_matches(path_to_file):\n",
    "    with open(path_to_file) as fin:\n",
    "        for line in fin: \n",
    "            yield json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пути к файлам, размеры файлов\n",
    "PATH_TR, TOTAL_TR = 'train_matches.jsonl', 39675\n",
    "PATH_TE, TOTAL_TE = 'test_matches.jsonl', 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"признаки.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Целевой признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dca9d2acd0e4b2796062939fae61c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39675.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "target_L = []\n",
    "idxs = []\n",
    "for MATCH in tqdm_notebook(read_matches(PATH_TR), total = TOTAL_TR):    \n",
    "    target_L.append((MATCH['match_id_hash'], MATCH['targets']['radiant_win']))\n",
    "    idxs.append(MATCH['match_id_hash'])\n",
    "y_tr = pd.DataFrame.from_records(target_L).set_index(0)[1].astype(int).values\n",
    "empty_df = pd.DataFrame(index = idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции для сбора статистики:\n",
    "\n",
    "* глобальной\n",
    "* командным сражениям\n",
    "* целевым объектам\n",
    "* игрокам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _collect_globals(PATH_TR, TOTAL_TR):\n",
    "    \n",
    "    D1 = defaultdict(list)\n",
    "    \n",
    "    # проходим по матчам\n",
    "    for MATCH in tqdm_notebook(read_matches(PATH_TR), total = TOTAL_TR):  \n",
    "\n",
    "        # сохраняем идентификатор матча\n",
    "        idx = MATCH['match_id_hash']\n",
    "\n",
    "        # время матча, типа лобби, тип игры\n",
    "        D1['game_time'].append((idx, MATCH['game_time']))\n",
    "        D1['game_mode'].append((idx, MATCH['game_mode']))\n",
    "        D1['lobby_type'].append((idx, MATCH['lobby_type']))\n",
    "\n",
    "        # чат по командам (длина переписки, интесивность переписки)\n",
    "        _df = pd.DataFrame.from_records(MATCH['chat'])\n",
    "        try:\n",
    "            _df['time'] = _df['time'].abs()\n",
    "            _df['text'] = _df['text'].apply(len)\n",
    "            _df['player_slot'] = _df['player_slot'].apply(lambda x: 'r' if x < 100 else 'd')\n",
    "\n",
    "            chat_len = _df.groupby('player_slot')['text'].sum()\n",
    "            chat_activity = _df.groupby('player_slot')['time'].apply(lambda x: np.diff(sorted(x)).mean())\n",
    "\n",
    "            D1['chat'].append((idx, chat_len['r'], chat_len['d'], chat_activity['r'], chat_activity['d']))\n",
    "        except:\n",
    "            D1['chat'].append((idx, np.nan, np.nan, np.nan, np.nan))    \n",
    "    \n",
    "                \n",
    "    return D1\n",
    "\n",
    "def _collect_teamfights(PATH_TR, TOTAL_TR):\n",
    "    \n",
    "    D2 = defaultdict(list)\n",
    "    # проходим по матчам\n",
    "    for MATCH in tqdm_notebook(read_matches(PATH_TR), total = TOTAL_TR):  \n",
    "\n",
    "        # сохраняем идентификатор матча\n",
    "        idx = MATCH['match_id_hash']        \n",
    "\n",
    "        # командные сражения (teamfights)        \n",
    "        # по тимфайтам в матче\n",
    "        for tf_idx, tf in enumerate(MATCH['teamfights']):\n",
    "\n",
    "            # начало, конец, время последней смерти, число смертей в тимфайте\n",
    "            D2['tf_total'].append((idx, tf_idx, tf['start'], tf['end'], tf['last_death'], tf['deaths']))\n",
    "\n",
    "            # проходим по каждому игроку\n",
    "            for player_idx, player in enumerate(tf['players']):\n",
    "\n",
    "                # определяем команду, за которую играет игрок\n",
    "                team = 'r' if player_idx<=4 else 'd'\n",
    "\n",
    "                # собираем использованные умения, предметы, убийства\n",
    "                for key in ('ability_uses', 'item_uses', 'killed'):\n",
    "                    for k, v in player[key].items():\n",
    "                        D2['tf_'+key].append((idx, team, k, v))\n",
    "\n",
    "                # собираем координаты смертей\n",
    "                for k, v in player['deaths_pos'].items():\n",
    "                    for k2, v2 in v.items():\n",
    "                        D2['tf_deaths_pos'].append((idx, team, k, k2, v2))  \n",
    "\n",
    "                # собираем смерти, выкупы, урон, восстановление здоровья, изменение золота, изменение опыта\n",
    "                for key in ('deaths', 'buybacks', 'damage', 'healing', 'gold_delta', 'xp_delta'):\n",
    "                    D2['tf_'+key].append((idx, team, player[key]))\n",
    "                    \n",
    "    return D2\n",
    "\n",
    "def _collect_objectives(PATH_TR, TOTAL_TR):\n",
    "    \n",
    "    L =[]\n",
    "    \n",
    "    # проходим по матчам\n",
    "    for MATCH in tqdm_notebook(read_matches(PATH_TR), total = TOTAL_TR):  \n",
    "\n",
    "        # сохраняем идентификатор матча\n",
    "        idx = MATCH['match_id_hash']\n",
    "        \n",
    "        # целевые объекты (objectives)    \n",
    "        for obj in MATCH['objectives']:\n",
    "            obj['idx'] = idx\n",
    "            L.append(obj)\n",
    "            \n",
    "    return L\n",
    "\n",
    "def _collect_players(PATH_TR, TOTAL_TR):\n",
    "    \n",
    "    D4 = defaultdict(list)\n",
    "    \n",
    "    # проходим по матчам\n",
    "    for MATCH in tqdm_notebook(read_matches(PATH_TR), total = TOTAL_TR):  \n",
    "\n",
    "        # сохраняем идентификатор матча\n",
    "        idx = MATCH['match_id_hash'] \n",
    "        \n",
    "        # игроки\n",
    "        for player_idx, player in enumerate(MATCH['players']):\n",
    "            team = 'r' if player_idx<=4 else 'd'\n",
    "\n",
    "            # числовые статистики\n",
    "            for key in ['obs_placed', 'sen_placed', 'creeps_stacked', 'camps_stacked', 'rune_pickups', 'firstblood_claimed',\n",
    "                        'teamfight_participation', 'towers_killed', 'roshans_killed', 'observers_placed', 'stuns',\n",
    "                        'gold', 'lh', 'xp',  'health', 'max_health', 'max_mana', 'level', 'kills', 'deaths', 'assists',\n",
    "                        'denies', 'nearby_creep_death_count', 'hero_id', 'x', 'y']:\n",
    "                D4['player_'+key].append((idx, team, player[key]))\n",
    "\n",
    "            # айди аккаунта (некоторые игроки - реальные люди,  некоторые - боты)  \n",
    "            D4['player_account_id_hash'].append((idx, team, player['account_id_hash']))\n",
    "\n",
    "            # прокачка умений героя\n",
    "            for upg in player['ability_upgrades']:\n",
    "                upg['idx'] = idx\n",
    "                upg['team'] = team\n",
    "                D4['player_ability_upgrades'].append(upg)\n",
    "\n",
    "            # использованные умения, предметы\n",
    "            for key in ('ability_uses', 'item_uses'):\n",
    "                for k, v in player[key].items():\n",
    "                    D4['player_'+key].append((idx, team, k, v))     \n",
    "\n",
    "            # причины получения золота, активность, серии убийств, мульти-убийства, пинги, руны, причины получения опыта\n",
    "            for key in ['actions', 'gold_reasons', 'kill_streaks', 'life_state', 'multi_kills', 'pings', 'runes', 'xp_reasons']:\n",
    "                for k, v in player[key].items():\n",
    "                    D4['player_'+key].append((idx, team, k, v))  \n",
    "\n",
    "            # логи выкупов\n",
    "            for bb_log in player['buyback_log']:\n",
    "                D4['player_buyback_log'].append((idx, 'r' if bb_log['player_slot']<100 else 'd', np.abs(bb_log['time'])))\n",
    "\n",
    "\n",
    "            for key in ('sen_log', 'obs_log', 'sen_left_log', 'obs_left_log'):\n",
    "                for log in player[key]:\n",
    "                    D4['player_'+key].append((idx, 'r' if log['player_slot']<100 else 'd', np.abs(log['time']),\\\n",
    "                                             log['x'], log['y'], log['z']))\n",
    "\n",
    "            # логи рун\n",
    "            for log in player['runes_log']:\n",
    "                log['idx'] = idx\n",
    "                log['team'] = team\n",
    "                D4['player_runes_log'].append(log)\n",
    "\n",
    "            # логи покупок\n",
    "            for log in player['purchase_log']:\n",
    "                log['idx'] = idx\n",
    "                log['team'] = team\n",
    "                log['time'] = np.abs(log['time'])\n",
    "                D4['player_purchase_log'].append(log)\n",
    "\n",
    "            # логи тотемов\n",
    "            for key in ('obs', 'sen'):\n",
    "                for k, v in player[key].items():\n",
    "                    for k2, v2 in v.items():\n",
    "                        D4['player_'+key].append((idx, team, k, k2, v2))\n",
    "\n",
    "            # золото, опыт, денаи, ластхиты с течением времени            \n",
    "            for key in ('gold_t', 'xp_t', 'dn_t', 'lh_t'):\n",
    "                for ts_idx, ts_value in enumerate(player[key]):\n",
    "                    D4['player_'+key].append((idx, team, ts_idx, ts_value))\n",
    "\n",
    "            # покупки\n",
    "            for k, v in player['purchase'].items():\n",
    "                D4['player_purchase'].append((idx, team, k, v))\n",
    "\n",
    "            # инвентарь\n",
    "            for item in player['hero_inventory']:\n",
    "                try:\n",
    "                    D4['player_hero_invenntory'].append((idx, team, item['id'], item['num_charges']))\n",
    "                except:\n",
    "                    D4['player_hero_invenntory'].append((idx, team, item['id'], 0))\n",
    "\n",
    "            # урон\n",
    "            for k, v in player['damage'].items():\n",
    "                D4['player_damage'].append((idx, team, k, v))\n",
    "            \n",
    "    return D4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Признаки (глобальная статистика)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30b6c05499b4aaa9b232ae08b1e1417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39675.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_glob_tr = _collect_globals(PATH_TR, TOTAL_TR)\n",
    "\n",
    "L_glob = []\n",
    "for k, v in D_glob_tr.items():\n",
    "    L_glob.append(empty_df.join(pd.DataFrame.from_records(v).set_index(0)))\n",
    "X_glob_tr = np.column_stack(L_glob)\n",
    "\n",
    "del D_glob_tr, L_glob\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Признаки (командные сражения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6857c39153443d9c71d4617fa02814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39675.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "D_tf_tr = _collect_teamfights(PATH_TR, TOTAL_TR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5dbefdd699f4cad84810227483d0804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29618.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df = pd.DataFrame.from_records(D_tf_tr['tf_total'])\n",
    "_df.columns = ['idx', 'tf_idx', 'start', 'end', 'last_death', 'deaths']\n",
    "_df.loc[:, ['start', 'end', 'last_death']] = _df[['start', 'end', 'last_death']].abs()\n",
    "\n",
    "L_tf = []\n",
    "for _idx, _subdf in tqdm_notebook(_df.groupby('idx')):\n",
    "    \n",
    "    # число смертей до определенного отрезка матча\n",
    "    _feats = pd.Series({ts:_subdf[(_subdf['start'] // 60) <= ts]['deaths'].sum() for ts in np.unique(_subdf['start'] // 60)})\\\n",
    "               .to_frame(_idx).T\n",
    "    \n",
    "    # средняя длительность сражений\n",
    "    _feats['duration'] = (_subdf['end'] - _subdf['start']).mean()\n",
    "    \n",
    "    # средняя доля отрезка времени с момента последней смерти в длительности сражения \n",
    "    _feats['last_death_to_end'] = (_subdf['last_death'] / _subdf['end']).mean()\n",
    "    \n",
    "    L_tf.append(_feats)\n",
    "    \n",
    "X1_tf_tr = np.column_stack([empty_df.join(_df.groupby('idx')['tf_idx'].nunique().to_frame('nuniques')),\\\n",
    "                            empty_df.join(pd.concat(L_tf))])\n",
    "\n",
    "del L_tf, _df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f08f6b22c34760b233838969e287fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bags_abil_item=[]\n",
    "# мешки использованных умений и айтемов \n",
    "for key in tqdm_notebook(('tf_ability_uses', 'tf_item_uses')):\n",
    "    _df = pd.DataFrame.from_records(D_tf_tr[key])\n",
    "    _df[4] = _df[1].replace({'r':1, 'd':-1}) * _df[3]\n",
    "    bags_abil_item.append(empty_df.join(_df.groupby([0, 2])[4].sum().unstack()))\n",
    "    bags_abil_item.append(empty_df.join(_df.groupby([0, 2])[4].mean().unstack()))\n",
    "    \n",
    "X2_tf_tr = np.column_stack(bags_abil_item)\n",
    "\n",
    "del bags_abil_item, _df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee07848dcc2a44749803c5e88d7d269b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_L = []\n",
    "for key in tqdm_notebook(('tf_deaths', 'tf_buybacks', 'tf_damage',\\\n",
    "                          'tf_healing', 'tf_gold_delta', 'tf_xp_delta')):\n",
    "    _df = pd.DataFrame.from_records(D_tf_tr[key])\n",
    "    _df[3] = _df[1].replace({'r':1, 'd':-1}) * _df[2]\n",
    "    counts_L.append(empty_df.join(_df.groupby(0)[3].sum().to_frame()))\n",
    "    \n",
    "X3_tf_tr = np.column_stack(counts_L)\n",
    "\n",
    "del counts_L, _df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df = pd.DataFrame.from_records(D_tf_tr['tf_deaths_pos'])\n",
    "\n",
    "_df['xy'] = (_df[2].astype(int)/10).round().astype(int).astype(str) +'_'+\\\n",
    "            (_df[3].astype(int)/10).round().astype(int).astype(str)\n",
    "\n",
    "X4_tf_tr = np.column_stack([empty_df.join(_df.groupby([0, 'xy'])[4].sum().unstack()),\\\n",
    "                            empty_df.join(_df.groupby([0, 'xy'])[4].mean().unstack())])\n",
    "\n",
    "del _df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del D_tf_tr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Признаки (целевые объекты)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e71b14a03084411a49ec0cd9e6c45ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39675.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_obj_tr = _collect_objectives(PATH_TR, TOTAL_TR)\n",
    "\n",
    "_df = pd.DataFrame.from_records(L_obj_tr)\n",
    "\n",
    "_df.loc[_df['team'].isna(), 'flag'] = _df[_df['team'].isna()]['player_slot'].apply(lambda x: 2 if x<100 else 3)\n",
    "_df.loc[~_df['team'].isna(), 'flag'] = _df[~_df['team'].isna()]['team']\n",
    "_df.loc[_df['flag'].isin([60, 100]), 'flag'] = _df[_df['flag'].isin([60, 100])]['slot'].apply(lambda x: 2 if x<=4 else 3)\n",
    "_df['flag'] = _df['flag'].replace({2:1, 3:-1})\n",
    "_df['time'] = _df['time'].abs()\n",
    "\n",
    "L = []\n",
    "L.append(empty_df.join(_df.groupby(['idx', 'type'])['flag'].sum().unstack()))\n",
    "L.append(empty_df.join(_df.groupby(['idx', 'type'])['flag'].mean().unstack()))\n",
    "\n",
    "X_obj_tr = np.column_stack(L)\n",
    "\n",
    "del L_obj_tr, L, _df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Признаки (игроки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818e139c455b45a2987dd205dd1f1d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39675.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "D_player_tr = _collect_players(PATH_TR, TOTAL_TR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec40509c43af48e497feb8617195d60c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b32a3cf81e54609a5705ad758283a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ed8c3594524792b1cdcc7c5343fe62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466cca7cecc44c82967fff5f3da230bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6df6f81ca6f45018d6b840517e27050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39675.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9cd1d867264ac1a15caa7572520766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "L = []\n",
    "for key in tqdm_notebook(['player_obs_placed', 'player_sen_placed', 'player_creeps_stacked', 'player_camps_stacked',\\\n",
    "                          'player_rune_pickups', 'player_firstblood_claimed',\n",
    "                          'player_teamfight_participation', 'player_towers_killed',\\\n",
    "                          'player_roshans_killed', 'player_observers_placed', 'player_stuns',\n",
    "                          'player_gold', 'player_lh', 'player_xp',  'player_health', 'player_max_health',\\\n",
    "                          'player_max_mana', 'player_level', 'player_kills', 'player_deaths', 'player_assists',\n",
    "                          'player_denies', 'player_nearby_creep_death_count']):\n",
    "    _df = pd.DataFrame.from_records(D_player_tr[key])\n",
    "    _df[3] = _df[1].replace({'r':1, 'd':-1}) * _df[2]\n",
    "    L.append(empty_df.join(_df.groupby(0)[3].sum().to_frame()))\n",
    "    L.append(empty_df.join(_df.groupby(0)[3].mean().to_frame()))\n",
    "    \n",
    "for key in tqdm_notebook(['player_hero_id', 'player_x', 'player_y']):\n",
    "    _df = pd.DataFrame.from_records(D_player_tr[key])\n",
    "    _df[1] = _df[1].replace({'r':1, 'd':-1})\n",
    "    L.append(empty_df.join(_df.groupby([0, 2])[1].sum().unstack()))\n",
    "\n",
    "_df= pd.DataFrame.from_records(D_player_tr['player_ability_upgrades'])\n",
    "L.append(empty_df.join(_df.groupby(['idx', 'team'])['time'].apply(lambda x: np.diff(sorted(x)).mean()).unstack()))\n",
    "\n",
    "for key in tqdm_notebook(('player_ability_uses', 'player_item_uses')):\n",
    "    _df= pd.DataFrame.from_records(D_player_tr[key])\n",
    "    _df[4] = _df[1].replace({'r':1,'d':-1})* _df[3]\n",
    "    L.append(empty_df.join(_df.groupby([0,2])[4].sum().unstack()))\n",
    "    L.append(empty_df.join(_df.groupby([0,2])[4].mean().unstack()))  \n",
    "    \n",
    "for key in tqdm_notebook(['player_actions', 'player_gold_reasons', 'player_kill_streaks',\\\n",
    "            'player_life_state', 'player_multi_kills', 'player_pings',\\\n",
    "            'player_runes', 'player_xp_reasons']):\n",
    "    _df= pd.DataFrame.from_records(D_player_tr[key])\n",
    "    _df[4] = _df[3]*_df[1].replace({'r':1, 'd':-1})\n",
    "    L.append(empty_df.join(_df.groupby([0, 2])[4].sum().unstack()))\n",
    "    L.append(empty_df.join(_df.groupby([0, 2])[4].mean().unstack()))\n",
    "    \n",
    "_df= pd.DataFrame.from_records(D_player_tr['player_buyback_log'])\n",
    "L.append(empty_df.join(_df.groupby([0,1])[2].apply(lambda x: np.diff(sorted(x)).mean()).unstack()))\n",
    "\n",
    "_df= pd.DataFrame.from_records(D_player_tr['player_runes_log'])\n",
    "L2,L3, L4=[], [], []\n",
    "for _idx, _subdf in tqdm_notebook(_df.groupby('idx')):\n",
    "    _subdf['team2']= _subdf['team'].replace({'r':1,'d':-1})\n",
    "    r_df= _subdf[_subdf['team']=='r']\n",
    "    d_df = _subdf[_subdf['team']=='d']\n",
    "    \n",
    "    L2.append(_subdf.groupby(['idx', 'key'])['team2'].sum().unstack())\n",
    "    L3.append(_subdf.groupby(['idx', 'key'])['team2'].mean().unstack())\n",
    "    L4.append((_idx,np.diff(sorted(r_df['time'])).mean()-np.diff(sorted(d_df['time'])).mean()))\n",
    "    \n",
    "L.append(empty_df.join(pd.concat(L2)))\n",
    "L.append(empty_df.join(pd.concat(L3)))\n",
    "L.append(empty_df.join(pd.DataFrame.from_records(L4).set_index(0)))\n",
    "\n",
    "for key in tqdm_notebook(('sen_log', 'obs_log', 'sen_left_log', 'obs_left_log')):\n",
    "    _df= pd.DataFrame.from_records(D_player_tr['player_'+key])\n",
    "    coords_df =(_df[[3, 4, 5]]/10).round().astype(int).astype(str)\n",
    "    _df['xyz'] = coords_df[3]+'_'+coords_df[4]+'_'+coords_df[5]\n",
    "    _df[6] = _df[1].replace({'r':1,'d':-1})\n",
    "    L.append(empty_df.join(_df.groupby([0, 'xyz'])[6].sum().unstack()))\n",
    "    L.append(empty_df.join(_df.groupby([0, 'xyz'])[6].mean().unstack()))\n",
    "\n",
    "_df= pd.DataFrame.from_records(D_player_tr['player_damage'])\n",
    "_df[4] = _df[1].replace({'r':1,'d':-1}) *_df[3]\n",
    "L.append(empty_df.join(_df.groupby([0, 2])[4].sum().unstack()))\n",
    "L.append(empty_df.join(_df.groupby([0, 2])[4].mean().unstack()))     \n",
    "\n",
    "X_player_tr = pd.concat(L,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr = np.column_stack([X_glob_tr, X1_tf_tr, X2_tf_tr, X3_tf_tr, X4_tf_tr, X_obj_tr, X_player_tr])\n",
    "del X_glob_tr, X1_tf_tr, X2_tf_tr, X3_tf_tr, X4_tf_tr, X_obj_tr, X_player_tr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число признаков = 5059\n"
     ]
    }
   ],
   "source": [
    "print('Число признаков = {}'.format(X_tr.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector():\n",
    "    def __init__(self, estimator,\n",
    "                       metric,\\\n",
    "                       larger_is_better,\\\n",
    "                       cv, \n",
    "                       use_values,\n",
    "                       use_recursion,\n",
    "                       fill_na,\\\n",
    "                       show_progress, \n",
    "                       early_stopping = None):\n",
    "        '''\n",
    "        Инициализирует модель для отбора признаков\n",
    "        \n",
    "        Параметры:\n",
    "            1) estimator - модель\n",
    "            2) metric - метрика качества (названия метрик sklearn + может быть кастомная)\n",
    "            3) larger_is_better - критерий оптимизации (чем больше, тем лучше)\n",
    "            4) cv - схема валидации\n",
    "            5) use_values - индексы столбцов, в которых требуется отобрать значения\n",
    "            6) use_recursion - использовать рекурсию в отборе\n",
    "            7) fill_na - значение, которым заполняются np.nan\n",
    "            8) show_progress - печатать результаты валидации\n",
    "            9) early_stopping - число итераций без улучшения метрики для ранней остановки отбора\n",
    "        Возвращает:\n",
    "            1) fit - производит отбор признаков\n",
    "            2) transform - оставляет отобранные признаки\n",
    "            3) return_self - возвращает \n",
    "                - best_features - отобранные признаки(список)\n",
    "                - D_best_features - отобранные значения признаков (словарь: {признак:значения})\n",
    "                - best_score - лучшее значение метрики\n",
    "        '''\n",
    "        self.estimator = estimator\n",
    "        self.metric = metric\n",
    "        self.cv = cv\n",
    "        self.use_values = use_values        \n",
    "        self.use_recursion = use_recursion\n",
    "        self.show_progress = show_progress\n",
    "        self.early_stopping = early_stopping\n",
    "        self.fill_na = fill_na\n",
    "        self.larger_is_better = larger_is_better\n",
    "    def fit(self, X, Y):        \n",
    "        flag = isinstance(X[:, 0], csc_matrix)\n",
    "        # список с результатами валидации\n",
    "        column_value_score = []\n",
    "        # проходим по признакам\n",
    "        for i in tqdm_notebook(range(X.shape[1])):\n",
    "            # если формат матрицы признаков == csc_matrix\n",
    "            if flag:\n",
    "                # выбираем столбец, преобразуем\n",
    "                ser = pd.DataFrame(X[:, i].todense())[0].values.flatten()\n",
    "            # если формат != csc_matrix\n",
    "            else:\n",
    "                # выбираем столбец\n",
    "                ser = X[:, i]        \n",
    "            # если столбец в списке с проверкой значений \n",
    "            if self.use_values is not None:                \n",
    "                if i in self.use_values:\n",
    "                    # уникальные значения столбца\n",
    "                    unique_values = np.unique(ser)  \n",
    "                    # валидируем каждое значение\n",
    "                    for val in unique_values:\n",
    "                        _x = np.int32(ser==val).reshape(-1,1)\n",
    "                        column_value_score.append((i, val,\\\n",
    "                                                   cross_val_score(self.estimator,\\\n",
    "                                                                   _x, Y,\\\n",
    "                                                                   scoring = self.metric,\\\n",
    "                                                                   cv = self.cv).mean()))\n",
    "                else: \n",
    "                    # валидируем столбец\n",
    "                    column_value_score.append((i, None,\\\n",
    "                                               cross_val_score(self.estimator,\\\n",
    "                                                               _x, Y,\\\n",
    "                                                               scoring = self.metric,\\\n",
    "                                                               cv = self.cv).mean()))\n",
    "            else:\n",
    "                # валидируем столбец\n",
    "                    column_value_score.append((i, None,\\\n",
    "                                               cross_val_score(self.estimator,\\\n",
    "                                                               ser.reshape(-1,1), Y,\\\n",
    "                                                               scoring = self.metric,\\\n",
    "                                                               cv = self.cv).mean()))\n",
    "                \n",
    "\n",
    "        # признаки и значения признаков в порядке убывания валидации\n",
    "        order = np.array(sorted(column_value_score, key = lambda x: x[-1], reverse = True))[:, :2]             \n",
    "        # список лучших признаков\n",
    "        best_features = []\n",
    "        # словарь лучших значений признаков\n",
    "        D_best_features = defaultdict(list)\n",
    "        # список с признаками, не давшими прироста\n",
    "        to_drop = []\n",
    "        \n",
    "        # лучшее значение метрики\n",
    "        if self.larger_is_better:\n",
    "            best_score = 0\n",
    "        else:\n",
    "            best_score = np.inf            \n",
    "        counter = 0\n",
    "        # проходим по признакам и значениям признаков в порядке убывания валидации\n",
    "        for feature, feature_value in tqdm_notebook(order):   \n",
    "\n",
    "            # добавляем текущие признаки/значения\n",
    "            if feature_value is None:\n",
    "                best_features.append(feature)               \n",
    "            else:\n",
    "                D_best_features[feature].append(feature_value)\n",
    "\n",
    "            # обновляем матрицы\n",
    "            L = []\n",
    "            for k, v in D_best_features.items():\n",
    "                if isinstance(X[:, k], csc_matrix):\n",
    "                    L.append(pd.DataFrame(X[:, k].tocsc().todense())[0].apply(lambda x: x if x in v else self.fill_na))\n",
    "                else:\n",
    "                    L.append(pd.Series(X[:, k].flatten()).apply(lambda x: x if x in v else self.fill_na))\n",
    "\n",
    "            if flag:\n",
    "                if (len(best_features)>0) & (len(L)>0):\n",
    "                    _X = csc_matrix(hstack([X[:, best_features], csc_matrix(np.column_stack(L)) ]))\n",
    "                elif (len(best_features)==0) & (len(L)>0):\n",
    "                    _X = csc_matrix(np.column_stack(L))\n",
    "                elif (len(best_features)>0) & (len(L)==0):\n",
    "                    _X = csc_matrix(X[:, best_features])                    \n",
    "                        \n",
    "            else:\n",
    "                if (len(best_features)>0) & (len(L)>0):\n",
    "                    _X = np.column_stack([X[:, best_features], np.column_stack(L)])\n",
    "                elif (len(best_features)==0) & (len(L)>0):\n",
    "                    _X = np.column_stack(L)\n",
    "                elif (len(best_features)>0) & (len(L)==0):\n",
    "                    _X = X[:, best_features] \n",
    "            # считаем валидацию    \n",
    "            current_score = cross_val_score(self.estimator, _X, Y, scoring = self.metric, cv = self.cv).mean()\n",
    "            # если метрика улучшилась\n",
    "            if self.larger_is_better:\n",
    "                if current_score>best_score:\n",
    "                    # обновляем лучшую метрику\n",
    "                    best_score = current_score\n",
    "                    counter = 0\n",
    "                    # печатаем \n",
    "                    if self.show_progress:\n",
    "                        print('new best_score = {}'.format(best_score))\n",
    "                # если метрика не улучшилась\n",
    "                else: \n",
    "                    counter+=1\n",
    "                    # удаляем признак/значение\n",
    "                    if feature_value is None:\n",
    "                        best_features = [val for val in best_features if val != feature]\n",
    "                        to_drop.append((feature, None))\n",
    "                    else:\n",
    "                        D_best_features[feature] = [val for val in D_best_features[feature] if val != feature_value]    \n",
    "                        to_drop.append((feature, feature_value))\n",
    "                    if counter == self.early_stopping:\n",
    "                        break\n",
    "            else:\n",
    "                if current_score<best_score:\n",
    "                    # обновляем лучшую метрику\n",
    "                    best_score = current_score\n",
    "                    counter = 0\n",
    "                    # печатаем \n",
    "                    if self.show_progress:\n",
    "                        print('new best_score = {}'.format(best_score))\n",
    "                    # если метрика не улучшилась\n",
    "                else: \n",
    "                    counter+=1\n",
    "                    # удаляем признак/значение\n",
    "                    if feature_value is None:\n",
    "                        best_features = [val for val in best_features if val != feature]\n",
    "                        to_drop.append((feature, None))\n",
    "                    else:\n",
    "                        D_best_features[feature] = [val for val in D_best_features[feature] if val != feature_value]    \n",
    "                        to_drop.append((feature, feature_value))\n",
    "                    if counter == self.early_stopping:\n",
    "                        break\n",
    "\n",
    "        if self.use_recursion:\n",
    "            # запускаем бесконечный цикл\n",
    "            while True:\n",
    "                # списки лучших признаков до и после\n",
    "                to_drop_before = to_drop\n",
    "                to_drop_after = []\n",
    "                # проходим по признакам и значениям признаков в порядке убывания валидации\n",
    "                for feature, feature_value in tqdm_notebook(to_drop_before):   \n",
    "                    # добавляем текущие признаки/значения\n",
    "                    if feature_value is None:\n",
    "                        best_features.append(feature)               \n",
    "                    else:\n",
    "                        D_best_features[feature].append(feature_value)\n",
    "\n",
    "                    # обновляем матрицы\n",
    "                    L = []\n",
    "                    for k, v in D_best_features.items():\n",
    "                        if isinstance(X[:, k], csc_matrix):\n",
    "                            L.append(pd.DataFrame(X[:, k].tocsc().todense())[0].apply(lambda x: x if x in v else self.fill_na))\n",
    "                        else:\n",
    "                            L.append(pd.Series(X[:, k].flatten()).apply(lambda x: x if x in v else self.fill_na))\n",
    "\n",
    "                    if flag:\n",
    "                        if (len(best_features)>0) & (len(L)>0):\n",
    "                            _X = csc_matrix(hstack([X[:, best_features], csc_matrix(np.column_stack(L)) ]))\n",
    "                        elif (len(best_features)==0) & (len(L)>0):\n",
    "                            _X = csc_matrix(np.column_stack(L))\n",
    "                        elif (len(best_features)>0) & (len(L)==0):\n",
    "                            _X = csc_matrix(X[:, best_features])                    \n",
    "\n",
    "                    else:\n",
    "                        if (len(best_features)>0) & (len(L)>0):\n",
    "                            _X = np.column_stack([X[:, best_features], np.column_stack(L)])\n",
    "                        elif (len(best_features)==0) & (len(L)>0):\n",
    "                            _X = np.column_stack(L)\n",
    "                        elif (len(best_features)>0) & (len(L)==0):\n",
    "                            _X = X[:, best_features] \n",
    "\n",
    "                    # считаем валидацию    \n",
    "                    current_score = cross_val_score(self.estimator, _X, Y, scoring = self.metric, cv = self.cv).mean()\n",
    "                    \n",
    "                    if self.larger_is_better:\n",
    "                        if current_score>best_score:\n",
    "                            # обновляем лучшую метрику\n",
    "                            best_score = current_score\n",
    "                            counter = 0\n",
    "                            # печатаем \n",
    "                            if self.show_progress:\n",
    "                                print('new best_score = {}'.format(best_score))\n",
    "                            # если метрика не улучшилась\n",
    "                        else: \n",
    "                            # удаляем признак/значение\n",
    "                            if feature_value is None:\n",
    "                                best_features = [val for val in best_features if val != feature]\n",
    "                                to_drop_after.append((feature, None))\n",
    "                            else:\n",
    "                                D_best_features[feature] = [val for val in D_best_features[feature] if val != feature_value]    \n",
    "                                to_drop_after.append((feature, feature_value))\n",
    "                    else:\n",
    "                        if current_score<best_score:\n",
    "                            # обновляем лучшую метрику\n",
    "                            best_score = current_score\n",
    "                            counter = 0\n",
    "                            # печатаем \n",
    "                            if self.show_progress:\n",
    "                                print('new best_score = {}'.format(best_score))\n",
    "                        else: \n",
    "                            # удаляем признак/значение\n",
    "                            if feature_value is None:\n",
    "                                best_features = [val for val in best_features if val != feature]\n",
    "                                to_drop_after.append((feature, None))\n",
    "                            else:\n",
    "                                D_best_features[feature] = [val for val in D_best_features[feature] if val != feature_value]    \n",
    "                                to_drop_after.append((feature, feature_value))\n",
    "                    \n",
    "\n",
    "                # если списки одинаковые, останавливаем отбор\n",
    "                if len(to_drop_after) == len(to_drop_before):\n",
    "                    break\n",
    "                # если разные - обновляем списки до и после\n",
    "                else:\n",
    "                    to_drop_before = to_drop_after\n",
    "                    to_drop_after = []\n",
    "                    \n",
    "        self.best_features = best_features\n",
    "        self.D_best_features = D_best_features\n",
    "        self.best_score =best_score\n",
    "        self.flag = flag\n",
    "    def transform(self, X):\n",
    "              \n",
    "        if len(self.best_features) !=0:\n",
    "            x1 = X[:, self.best_features]\n",
    "        else:\n",
    "            x1 = None\n",
    "        if len(list(self.D_best_features.keys())) !=0:\n",
    "            L=[]\n",
    "            for k, v in self.D_best_features.items():\n",
    "                if self.flag:\n",
    "                    L.append(pd.DataFrame(X[:, k].tocsc().todense())[0].apply(lambda x: x if x in v else self.fill_na))                    \n",
    "                else:\n",
    "                    L.append(pd.Series(X[:, k].flatten()).apply(lambda x: x if x in v else self.fill_na))\n",
    "            x2 = np.column_stack(L)\n",
    "        else:\n",
    "            x2 = None\n",
    "            \n",
    "        if (x1 is not None) & (x2 is not None):\n",
    "            if self.flag: \n",
    "                _X = csc_matrix(hstack([x1, x2]))\n",
    "            else:\n",
    "                _X = np.column_stack([x1, x2])\n",
    "                \n",
    "        if (x1 is not None) & (x2 is None):\n",
    "            _X = x1\n",
    "        if (x1 is None) & (x2 is not None):\n",
    "            if self.flag:\n",
    "                _X = csc_matrix(x2)\n",
    "            else:\n",
    "                _X = x2\n",
    "        return _X     \n",
    "        \n",
    "    def return_self(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=13\n",
    "X_tr = pd.DataFrame(X_tr).replace({np.inf:-1}).fillna(-1).values\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled_tr = scaler.fit_transform(X_tr)\n",
    "\n",
    "X_TR, X_HOLDOUT, Y_TR, Y_HOLDOUT = train_test_split(X_scaled_tr, y_tr, stratify = y_tr, test_size= .1, random_state = SEED)\n",
    "skf3= StratifiedKFold(3,random_state = SEED)\n",
    "logit_clf = LogisticRegression(random_state = SEED)\n",
    "lgb_clf = LGBMClassifier(random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46d1dacd98c4fffb3cc948eb1edd836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5059.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b518b3b0c82461f8815ddefc0869da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5059.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "selector = FeatureSelector(estimator = lgb_clf,\\\n",
    "                          metric = 'roc_auc',\\\n",
    "                          larger_is_better = True,\\\n",
    "                          cv = skf3,\\\n",
    "                          use_values = None,\\\n",
    "                          use_recursion = False,\\\n",
    "                          fill_na = -1,\\\n",
    "                          show_progress = False, \n",
    "                          early_stopping = None)            \n",
    "selector.fit(X_TR, Y_TR)     \n",
    "X_sel_scaled_tr = selector.transform(X_scaled_tr)\n",
    "X_sel_TR, X_sel_HOLD = selector.transform(X_TR), selector.transform(X_HOLDOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# лучший auc\n",
    "best_score = selector.return_self().best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### смешиваем предсказания моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84872ec7a4042109c1fa916adab7120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score blend = 0.83339\n",
      "best score blend = 0.83345\n",
      "best score blend = 0.83349\n",
      "best score blend = 0.83354\n",
      "best score blend = 0.83358\n",
      "best score blend = 0.83363\n",
      "best score blend = 0.83366\n",
      "best score blend = 0.83369\n",
      "best score blend = 0.83372\n",
      "best score blend = 0.83375\n",
      "best score blend = 0.83377\n",
      "best score blend = 0.83379\n",
      "best score blend = 0.83381\n",
      "best score blend = 0.83383\n",
      "best score blend = 0.83384\n",
      "best score blend = 0.83385\n",
      "best score blend = 0.83386\n",
      "best score blend = 0.83386\n",
      "best score blend = 0.83387\n",
      "best score blend = 0.83387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# вес1\n",
    "for w1 in tqdm_notebook(np.linspace(0, 1, 100)):\n",
    "    \n",
    "    # вес2\n",
    "    w2 = 1-w1\n",
    "    aucs = []\n",
    "    \n",
    "    # запускаем валидацию\n",
    "    for tr_idx, val_idx in skf3.split(X_sel_TR, Y_TR):\n",
    "        \n",
    "        xtr, xval = X_sel_TR[tr_idx], X_sel_TR[val_idx]\n",
    "        ytr, yval = Y_TR[tr_idx], Y_TR[val_idx]\n",
    "        \n",
    "        # фитим модели\n",
    "        lgb_clf.fit(xtr,ytr)\n",
    "        logit_clf.fit(xtr,ytr)\n",
    "\n",
    "        # делаем предсказания\n",
    "        lgb_predprob = lgb_clf.predict_proba(xval)[:, 1]\n",
    "        logit_predprob = logit_clf.predict_proba(xval)[:, 1]   \n",
    "        \n",
    "        # смешиваем предсказания\n",
    "        y_blend = lgb_predprob*w1 + logit_predprob*w2\n",
    "        \n",
    "        # сохраняем метрику\n",
    "        aucs.append(roc_auc_score(yval, y_blend))\n",
    "        \n",
    "    # средняя метрика смешанных предсказаний\n",
    "    mean_score = np.mean(aucs)\n",
    "    \n",
    "    # если метрика смешанных предскзаний лучше метрики бустинга\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_w1 = w1\n",
    "        print('best score blend = {:.5f}'.format(best_score))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вес lgb = 0.79, вес logit = 0.21\n"
     ]
    }
   ],
   "source": [
    "print('вес lgb = {:.2f}, вес logit = {:.2f}'.format(best_w1, 1-best_w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
