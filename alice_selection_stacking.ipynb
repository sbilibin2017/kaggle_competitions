{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание задачи:\n",
    "\n",
    "Будем решать задачу идентификации взломщика по его поведению в сети Интернет. Это сложная и интересная задача на стыке анализа данных и поведенческой психологии. В качестве примера, компания Яндекс решает задачу идентификации взломщика почтового ящика по его поведению. В двух словах, взломщик будет себя вести не так, как владелец ящика: он может не удалять сообщения сразу по прочтении, как это делал хозяин, он будет по-другому ставить флажки сообщениям и даже по-своему двигать мышкой. Тогда такого злоумышленника можно идентифицировать и \"выкинуть\" из почтового ящика, предложив хозяину войти по SMS-коду. Этот пилотный проект описан в статье на Хабрахабре. Похожие вещи делаются, например, в Google Analytics и описываются в научных статьях, найти можно многое по фразам \"Traversal Pattern Mining\" и \"Sequential Pattern Mining\".\n",
    "\n",
    "В этом соревновании будем решать похожую задачу: алгоритм будет анализировать последовательность из нескольких веб-сайтов, посещенных подряд одним и тем же человеком, и определять, Элис это или взломщик (кто-то другой).\n",
    "\n",
    "Данные собраны с прокси-серверов Университета Блеза Паскаля. \"A Tool for Classification of Sequential Data\", авторы Giacomo Kahn, Yannick Loiseau и Olivier Raynaud.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import vstack, hstack, csc_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, TimeSeriesSplit,\\\n",
    "                                    cross_val_score, cross_validate, GridSearchCV, ParameterGrid\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector():\n",
    "    def __init__(self, estimator,\n",
    "                       metric,\\\n",
    "                       larger_is_better,\\\n",
    "                       cv, \n",
    "                       use_values,\n",
    "                       use_recursion,\n",
    "                       fill_na,\\\n",
    "                       show_progress, \n",
    "                       early_stopping = None):\n",
    "        '''\n",
    "        Инициализирует модель для отбора признаков\n",
    "        \n",
    "        Параметры:\n",
    "            1) estimator - модель\n",
    "            2) metric - метрика качества (названия метрик sklearn + может быть кастомная)\n",
    "            3) larger_is_better - критерий оптимизации (чем больше, тем лучше)\n",
    "            4) cv - схема валидации\n",
    "            5) use_values - индексы столбцов, в которых требуется отобрать значения\n",
    "            6) use_recursion - использовать рекурсию в отборе\n",
    "            7) fill_na - значение, которым заполняются np.nan\n",
    "            8) show_progress - печатать результаты валидации\n",
    "            9) early_stopping - число итераций без улучшения метрики для ранней остановки отбора\n",
    "        Возвращает:\n",
    "            1) fit - производит отбор признаков\n",
    "            2) transform - оставляет отобранные признаки\n",
    "            3) return_self - возвращает \n",
    "                - best_features - отобранные признаки(список)\n",
    "                - D_best_features - отобранные значения признаков (словарь: {признак:значения})\n",
    "                - best_score - лучшее значение метрики\n",
    "        '''\n",
    "        self.estimator = estimator\n",
    "        self.metric = metric\n",
    "        self.cv = cv\n",
    "        self.use_values = use_values        \n",
    "        self.use_recursion = use_recursion\n",
    "        self.show_progress = show_progress\n",
    "        self.early_stopping = early_stopping\n",
    "        self.fill_na = fill_na\n",
    "        self.larger_is_better = larger_is_better\n",
    "    def fit(self, X, Y):        \n",
    "        flag = isinstance(X[:, 0], csc_matrix)\n",
    "        # список с результатами валидации\n",
    "        column_value_score = []\n",
    "        # проходим по признакам\n",
    "        for i in tqdm_notebook(range(X.shape[1])):\n",
    "            # если формат матрицы признаков == csc_matrix\n",
    "            if flag:\n",
    "                # выбираем столбец, преобразуем\n",
    "                ser = pd.DataFrame(X[:, i].todense())[0].values.flatten()\n",
    "            # если формат != csc_matrix\n",
    "            else:\n",
    "                # выбираем столбец\n",
    "                ser = X[:, i]        \n",
    "            # если столбец в списке с проверкой значений \n",
    "            if self.use_values is not None:                \n",
    "                if i in self.use_values:\n",
    "                    # уникальные значения столбца\n",
    "                    unique_values = np.unique(ser)  \n",
    "                    # валидируем каждое значение\n",
    "                    for val in unique_values:\n",
    "                        _x = np.int32(ser==val).reshape(-1,1)\n",
    "                        column_value_score.append((i, val,\\\n",
    "                                                   cross_val_score(self.estimator,\\\n",
    "                                                                   _x, Y,\\\n",
    "                                                                   scoring = self.metric,\\\n",
    "                                                                   cv = self.cv).mean()))\n",
    "                else: \n",
    "                    # валидируем столбец\n",
    "                    column_value_score.append((i, None,\\\n",
    "                                               cross_val_score(self.estimator,\\\n",
    "                                                               _x, Y,\\\n",
    "                                                               scoring = self.metric,\\\n",
    "                                                               cv = self.cv).mean()))\n",
    "            else:\n",
    "                # валидируем столбец\n",
    "                    column_value_score.append((i, None,\\\n",
    "                                               cross_val_score(self.estimator,\\\n",
    "                                                               ser.reshape(-1,1), Y,\\\n",
    "                                                               scoring = self.metric,\\\n",
    "                                                               cv = self.cv).mean()))\n",
    "                \n",
    "\n",
    "        # признаки и значения признаков в порядке убывания валидации\n",
    "        order = np.array(sorted(column_value_score, key = lambda x: x[-1], reverse = True))[:, :2]             \n",
    "        # список лучших признаков\n",
    "        best_features = []\n",
    "        # словарь лучших значений признаков\n",
    "        D_best_features = defaultdict(list)\n",
    "        # список с признаками, не давшими прироста\n",
    "        to_drop = []\n",
    "        \n",
    "        # лучшее значение метрики\n",
    "        if self.larger_is_better:\n",
    "            best_score = 0\n",
    "        else:\n",
    "            best_score = np.inf            \n",
    "        counter = 0\n",
    "        # проходим по признакам и значениям признаков в порядке убывания валидации\n",
    "        for feature, feature_value in tqdm_notebook(order):   \n",
    "\n",
    "            # добавляем текущие признаки/значения\n",
    "            if feature_value is None:\n",
    "                best_features.append(feature)               \n",
    "            else:\n",
    "                D_best_features[feature].append(feature_value)\n",
    "\n",
    "            # обновляем матрицы\n",
    "            L = []\n",
    "            for k, v in D_best_features.items():\n",
    "                if isinstance(X[:, k], csc_matrix):\n",
    "                    L.append(pd.DataFrame(X[:, k].tocsc().todense())[0].apply(lambda x: x if x in v else self.fill_na))\n",
    "                else:\n",
    "                    L.append(pd.Series(X[:, k].flatten()).apply(lambda x: x if x in v else self.fill_na))\n",
    "\n",
    "            if flag:\n",
    "                if (len(best_features)>0) & (len(L)>0):\n",
    "                    _X = csc_matrix(hstack([X[:, best_features], csc_matrix(np.column_stack(L)) ]))\n",
    "                elif (len(best_features)==0) & (len(L)>0):\n",
    "                    _X = csc_matrix(np.column_stack(L))\n",
    "                elif (len(best_features)>0) & (len(L)==0):\n",
    "                    _X = csc_matrix(X[:, best_features])                    \n",
    "                        \n",
    "            else:\n",
    "                if (len(best_features)>0) & (len(L)>0):\n",
    "                    _X = np.column_stack([X[:, best_features], np.column_stack(L)])\n",
    "                elif (len(best_features)==0) & (len(L)>0):\n",
    "                    _X = np.column_stack(L)\n",
    "                elif (len(best_features)>0) & (len(L)==0):\n",
    "                    _X = X[:, best_features] \n",
    "            # считаем валидацию    \n",
    "            current_score = cross_val_score(self.estimator, _X, Y, scoring = self.metric, cv = self.cv).mean()\n",
    "            # если метрика улучшилась\n",
    "            if self.larger_is_better:\n",
    "                if current_score>best_score:\n",
    "                    # обновляем лучшую метрику\n",
    "                    best_score = current_score\n",
    "                    counter = 0\n",
    "                    # печатаем \n",
    "                    if self.show_progress:\n",
    "                        print('new best_score = {}'.format(best_score))\n",
    "                # если метрика не улучшилась\n",
    "                else: \n",
    "                    counter+=1\n",
    "                    # удаляем признак/значение\n",
    "                    if feature_value is None:\n",
    "                        best_features = [val for val in best_features if val != feature]\n",
    "                        to_drop.append((feature, None))\n",
    "                    else:\n",
    "                        D_best_features[feature] = [val for val in D_best_features[feature] if val != feature_value]    \n",
    "                        to_drop.append((feature, feature_value))\n",
    "                    if counter == self.early_stopping:\n",
    "                        break\n",
    "            else:\n",
    "                if current_score<best_score:\n",
    "                    # обновляем лучшую метрику\n",
    "                    best_score = current_score\n",
    "                    counter = 0\n",
    "                    # печатаем \n",
    "                    if self.show_progress:\n",
    "                        print('new best_score = {}'.format(best_score))\n",
    "                    # если метрика не улучшилась\n",
    "                else: \n",
    "                    counter+=1\n",
    "                    # удаляем признак/значение\n",
    "                    if feature_value is None:\n",
    "                        best_features = [val for val in best_features if val != feature]\n",
    "                        to_drop.append((feature, None))\n",
    "                    else:\n",
    "                        D_best_features[feature] = [val for val in D_best_features[feature] if val != feature_value]    \n",
    "                        to_drop.append((feature, feature_value))\n",
    "                    if counter == self.early_stopping:\n",
    "                        break\n",
    "\n",
    "        if self.use_recursion:\n",
    "            # запускаем бесконечный цикл\n",
    "            while True:\n",
    "                # списки лучших признаков до и после\n",
    "                to_drop_before = to_drop\n",
    "                to_drop_after = []\n",
    "                # проходим по признакам и значениям признаков в порядке убывания валидации\n",
    "                for feature, feature_value in tqdm_notebook(to_drop_before):   \n",
    "                    # добавляем текущие признаки/значения\n",
    "                    if feature_value is None:\n",
    "                        best_features.append(feature)               \n",
    "                    else:\n",
    "                        D_best_features[feature].append(feature_value)\n",
    "\n",
    "                    # обновляем матрицы\n",
    "                    L = []\n",
    "                    for k, v in D_best_features.items():\n",
    "                        if isinstance(X[:, k], csc_matrix):\n",
    "                            L.append(pd.DataFrame(X[:, k].tocsc().todense())[0].apply(lambda x: x if x in v else self.fill_na))\n",
    "                        else:\n",
    "                            L.append(pd.Series(X[:, k].flatten()).apply(lambda x: x if x in v else self.fill_na))\n",
    "\n",
    "                    if flag:\n",
    "                        if (len(best_features)>0) & (len(L)>0):\n",
    "                            _X = csc_matrix(hstack([X[:, best_features], csc_matrix(np.column_stack(L)) ]))\n",
    "                        elif (len(best_features)==0) & (len(L)>0):\n",
    "                            _X = csc_matrix(np.column_stack(L))\n",
    "                        elif (len(best_features)>0) & (len(L)==0):\n",
    "                            _X = csc_matrix(X[:, best_features])                    \n",
    "\n",
    "                    else:\n",
    "                        if (len(best_features)>0) & (len(L)>0):\n",
    "                            _X = np.column_stack([X[:, best_features], np.column_stack(L)])\n",
    "                        elif (len(best_features)==0) & (len(L)>0):\n",
    "                            _X = np.column_stack(L)\n",
    "                        elif (len(best_features)>0) & (len(L)==0):\n",
    "                            _X = X[:, best_features] \n",
    "\n",
    "                    # считаем валидацию    \n",
    "                    current_score = cross_val_score(self.estimator, _X, Y, scoring = self.metric, cv = self.cv).mean()\n",
    "                    \n",
    "                    if self.larger_is_better:\n",
    "                        if current_score>best_score:\n",
    "                            # обновляем лучшую метрику\n",
    "                            best_score = current_score\n",
    "                            counter = 0\n",
    "                            # печатаем \n",
    "                            if self.show_progress:\n",
    "                                print('new best_score = {}'.format(best_score))\n",
    "                            # если метрика не улучшилась\n",
    "                        else: \n",
    "                            # удаляем признак/значение\n",
    "                            if feature_value is None:\n",
    "                                best_features = [val for val in best_features if val != feature]\n",
    "                                to_drop_after.append((feature, None))\n",
    "                            else:\n",
    "                                D_best_features[feature] = [val for val in D_best_features[feature] if val != feature_value]    \n",
    "                                to_drop_after.append((feature, feature_value))\n",
    "                    else:\n",
    "                        if current_score<best_score:\n",
    "                            # обновляем лучшую метрику\n",
    "                            best_score = current_score\n",
    "                            counter = 0\n",
    "                            # печатаем \n",
    "                            if self.show_progress:\n",
    "                                print('new best_score = {}'.format(best_score))\n",
    "                        else: \n",
    "                            # удаляем признак/значение\n",
    "                            if feature_value is None:\n",
    "                                best_features = [val for val in best_features if val != feature]\n",
    "                                to_drop_after.append((feature, None))\n",
    "                            else:\n",
    "                                D_best_features[feature] = [val for val in D_best_features[feature] if val != feature_value]    \n",
    "                                to_drop_after.append((feature, feature_value))\n",
    "                    \n",
    "\n",
    "                # если списки одинаковые, останавливаем отбор\n",
    "                if len(to_drop_after) == len(to_drop_before):\n",
    "                    break\n",
    "                # если разные - обновляем списки до и после\n",
    "                else:\n",
    "                    to_drop_before = to_drop_after\n",
    "                    to_drop_after = []\n",
    "                    \n",
    "        self.best_features = best_features\n",
    "        self.D_best_features = D_best_features\n",
    "        self.best_score =best_score\n",
    "        self.flag = flag\n",
    "    def transform(self, X):\n",
    "              \n",
    "        if len(self.best_features) !=0:\n",
    "            x1 = X[:, self.best_features]\n",
    "        else:\n",
    "            x1 = None\n",
    "        if len(list(self.D_best_features.keys())) !=0:\n",
    "            L=[]\n",
    "            for k, v in self.D_best_features.items():\n",
    "                if self.flag:\n",
    "                    L.append(pd.DataFrame(X[:, k].tocsc().todense())[0].apply(lambda x: x if x in v else self.fill_na))                    \n",
    "                else:\n",
    "                    L.append(pd.Series(X[:, k].flatten()).apply(lambda x: x if x in v else self.fill_na))\n",
    "            x2 = np.column_stack(L)\n",
    "        else:\n",
    "            x2 = None\n",
    "            \n",
    "        if (x1 is not None) & (x2 is not None):\n",
    "            if self.flag: \n",
    "                _X = csc_matrix(hstack([x1, x2]))\n",
    "            else:\n",
    "                _X = np.column_stack([x1, x2])\n",
    "                \n",
    "        if (x1 is not None) & (x2 is None):\n",
    "            _X = x1\n",
    "        if (x1 is None) & (x2 is not None):\n",
    "            if self.flag:\n",
    "                _X = csc_matrix(x2)\n",
    "            else:\n",
    "                _X = x2\n",
    "        return _X     \n",
    "        \n",
    "    def return_self(self):\n",
    "        return self\n",
    "    \n",
    "def _get_tfidf_and_time_features(df_tr, df_te, target_col, vectorizer):\n",
    "    '''\n",
    "    параметры:\n",
    "        1) df_tr - тренировочный датасет\n",
    "        2) df_te - тестовый датасет\n",
    "        3) target_col - колонка с целевой переменной (df_tr)\n",
    "    действия:\n",
    "        1) трансформирует сайты с помощью tfidf\n",
    "        2) извлекает признаки из даты\n",
    "    вывод:\n",
    "        1) _X_logit_tr, _X_logit_te - признаки для логистической регрессии\n",
    "        2) _X_lgb_tr, _X_lgb_te - признаки для бустинга\n",
    "        3) _y_tr - целевая переменная\n",
    "        4) to_check_values_idxs - индексы признаков, где необходимо отобрать значения\n",
    "    '''\n",
    "    \n",
    "    # уникальные сайты в тест части\n",
    "    unique_sites_te = pd.Series(df_te[SITES].values.flatten()).dropna().sort_values().unique()\n",
    "\n",
    "    # уникальные сайты, посещенные Элис\n",
    "    unique_sites_alice = pd.Series(df_tr[df_tr[target_col]==1][SITES].values.flatten()).dropna().sort_values().unique()\n",
    "\n",
    "    # сайты, которые оставляем\n",
    "    sites_to_use = np.intersect1d(unique_sites_te, unique_sites_alice)\n",
    "\n",
    "    # оставляем сайты, посещенные в тест части & посещенные Элис\n",
    "    sites_tr = df_tr[SITES].applymap(lambda x: x if x in sites_to_use else FILL_NA)\n",
    "    sites_te = df_te[SITES].applymap(lambda x: x if x in sites_to_use else FILL_NA)\n",
    "\n",
    "    # начало сессии \n",
    "    start_tr = df_tr[TIMES].min(1)\n",
    "    start_te = df_te[TIMES].min(1)\n",
    "\n",
    "    ts_columns = ['dayofyear', 'weekofyear', 'year', 'month',\\\n",
    "                  'day', 'dayofweek', 'hour']\n",
    "\n",
    "    D_ts = {}\n",
    "    # извлекаем признаки\n",
    "    for key, ts_df in zip(('tr', 'te'), (start_tr, start_te)):    \n",
    "        times_df = pd.DataFrame(np.column_stack([ts_df.dt.dayofyear,\\\n",
    "                             ts_df.dt.weekofyear,\\\n",
    "                             ts_df.dt.year,\\\n",
    "                             ts_df.dt.month,\\\n",
    "                             ts_df.dt.day,\\\n",
    "                             ts_df.dt.dayofweek,\\\n",
    "                             ts_df.dt.hour]))\n",
    "        times_df.columns = ts_columns\n",
    "        D_ts[key] = times_df\n",
    "\n",
    "    # оставляем значения из теста\n",
    "    for col in D_ts['tr'].columns:\n",
    "        values_to_use = np.unique(D_ts['te'][col])\n",
    "        D_ts['tr'][col] = D_ts['tr'][col].apply(lambda x: x if x in values_to_use else FILL_NA)    \n",
    "\n",
    "    # one hot encoding\n",
    "    ohe_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    ohe_encoder.fit(D_ts['tr'])\n",
    "\n",
    "    ts_ohe_tr = ohe_encoder.transform(D_ts['tr'])\n",
    "    ts_ohe_te = ohe_encoder.transform(D_ts['te'])\n",
    "\n",
    "    # готовим данные для tfidf\n",
    "    sites_full_str = pd.concat([sites_tr, sites_te], 0)\\\n",
    "                       .astype(int).astype(str)\\\n",
    "                       .apply(lambda row: '_'.join(row), axis =1)\n",
    "    \n",
    "    # продолжительность сессии (в секундах+log)\n",
    "    duration_log_tr = np.log1p((df_tr[TIMES].max(1) - df_tr[TIMES].min(1)) / np.timedelta64(1, 's'))\n",
    "    duration_log_te = np.log1p((df_te[TIMES].max(1) - df_te[TIMES].min(1)) / np.timedelta64(1, 's'))\n",
    "\n",
    "    # трансформируем сайты    \n",
    "    tfidf_full = csc_matrix(vectorizer.fit_transform(sites_full_str))\n",
    "    tfidf_tr, tfidf_te = tfidf_full[:len(df_tr)], tfidf_full[len(df_tr):]\n",
    "    # датасеты для лоигта\n",
    "    _X_logit_tr = csc_matrix(hstack([ts_ohe_tr, tfidf_tr, duration_log_tr.values.reshape(-1, 1)]))\n",
    "    _X_logit_te = csc_matrix(hstack([ts_ohe_te, tfidf_te, duration_log_te.values.reshape(-1, 1)]))        \n",
    "    # датасеты для бустинга\n",
    "    _X_lgb_tr = csc_matrix(hstack([D_ts['tr'], tfidf_tr, duration_log_tr.values.reshape(-1, 1)]))\n",
    "    _X_lgb_te = csc_matrix(hstack([D_ts['te'], tfidf_te, duration_log_te.values.reshape(-1, 1)]))\n",
    "    # таргет\n",
    "    _y_tr = np.array(y_tr)        \n",
    "    # индексы признаков, в которых надо тотбрать значения\n",
    "    to_check_values_idxs = np.arange(D_ts['tr'].shape[1]).tolist()\n",
    "    \n",
    "    return {'_X_logit_tr':_X_logit_tr, '_X_logit_te':_X_logit_te,\\\n",
    "            '_X_lgb_tr':_X_lgb_tr, '_X_lgb_te':_X_lgb_te,\\\n",
    "            '_y_tr':_y_tr, 'to_check_values_idxs':to_check_values_idxs}\n",
    "\n",
    "def _find_optimal_folding(y, cvs):    \n",
    "    # максимальные различия по фолдам\n",
    "    max_diffs_by_folds_L = []    \n",
    "    # итерируемся по числу фолдов\n",
    "    for cv in cvs:\n",
    "        # список с l1 нормами для среднего таргета на трейн и валидационном фолдах\n",
    "        l1_diff_L = []\n",
    "        for tr_idx, val_idx in cv.split(y):\n",
    "            l1_diff_L.append(np.abs(df_tr.iloc[tr_idx]['target'].mean() - df_tr.iloc[val_idx]['target'].mean()))\n",
    "        # максимальная l1 за всю валидацию\n",
    "        max_diffs_by_folds_L.append(np.max(l1_diff_L))\n",
    "    # минимизируем максимальный разброс --> получаем число фолдов\n",
    "    return cvs[np.argmin(max_diffs_by_folds_L)]\n",
    "\n",
    "class StackingEstimator():    \n",
    "    def __init__(self, models, cv, subsample, seed):\n",
    "        '''\n",
    "        models - список с ансамблем моделей\n",
    "        cvs - список с схемами валидации\n",
    "        n_iterations - итераций стекинга\n",
    "        subsamples - список с долями используемых признаков \n",
    "        seed - генератор случайных чисел\n",
    "        '''        \n",
    "        self.models = models\n",
    "        self.cv = cv        \n",
    "        self.subsamples = subsamples\n",
    "        self.seed = seed\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        1) обучаем модели на валидации\n",
    "        2) сохраняем обученные модели\n",
    "        '''        \n",
    "        nfeat = X.shape[1]\n",
    "        feat_idxs = np.arange(nfeat)        \n",
    "        estimators_use_idxs=[]\n",
    "        for model_idx, model in tqdm_notebook(enumerate(self.models), total = len(self.models)):\n",
    "            np.random.seed(model_idx+self.seed+1)\n",
    "            use_idxs = np.random.choice(feat_idxs, np.int32(np.around(nfeat*subsample)), replace = False)\n",
    "            for tr_idx, val_idx in cv.split(y):\n",
    "                model.fit(X[tr_idx][:, use_idxs], y[tr_idx])   \n",
    "                estimators_use_idxs.append((model, use_idxs))        \n",
    "        self.estimators_use_idxs = estimators_use_idxs\n",
    "    def get_metafeatures(self, X):\n",
    "        '''\n",
    "        с помощью обученных моделей получаем метапризнаки\n",
    "        '''\n",
    "        L = []    \n",
    "        for use_idxs, estimator in self.estimators_use_idxs:\n",
    "            try:\n",
    "                L.append(estimator.predict_proba(X[:, use_idxs])[:, 1])\n",
    "            except:\n",
    "                L.append(estimator.predict(X[:, use_idxs]))\n",
    "                \n",
    "        return np.column_stack(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pipeline.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сайты, время\n",
    "TIMES = ['time%d' % i for i in range(1, 11)]\n",
    "SITES = ['site%d' % i for i in range(1, 11)]\n",
    "\n",
    "# трейн, тест\n",
    "df_tr = pd.read_csv('train_sessions.csv', parse_dates = TIMES).set_index('session_id').sort_values('time1')\n",
    "df_te = pd.read_csv('test_sessions.csv', parse_dates = TIMES).set_index('session_id')\n",
    "\n",
    "# таргет\n",
    "y_tr = df_tr['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# константы\n",
    "SEED = 13\n",
    "FILL_NA = -1\n",
    "TRAIN_SHARE = .9\n",
    "IDX_SPLIT = np.int32(np.around(TRAIN_SHARE*len(df_tr)))\n",
    "NFOLDS_L = np.arange(3, 13)\n",
    "\n",
    "# модели\n",
    "lgb_clf = LGBMClassifier(random_state = SEED)\n",
    "logit_clf = LogisticRegression(random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# находим число фолдов, при котором абсолютный разброс среднего таргета в трейне и отложенной частях минимален\n",
    "# --> тестируем модель примерно на том, на чем обучали\n",
    "L_cvs = [TimeSeriesSplit(k) for k in range(3, 11)]\n",
    "tscv = _find_optimal_folding(df_tr['target'].iloc[:IDX_SPLIT], L_cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_param_grid = {'ngram_range':((1, 1), (1, 2), (1, 3), (1, 4), (1, 5)),\\\n",
    "                    'max_features':(10, 100, 200)}                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### перебор параметров tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d832513e644dacb3ce4ba654e20761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8187cdde46449da9926063c878931d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37493a25a5e4a6ca162f0a710c25457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9815e1b73a8143dea413672cb2857973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=71.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b262e17f5447038285f9c3ab8afee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd24379f44d43b0852afa1130bd9246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc411241edf44f68acc31dd8dbf9b505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ab5f1302514c628fbc68beff64a362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=161.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd69435ad66141dd8f48921905a1d42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=162.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc7b943f95b414eb0a2f22ca60584c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=162.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0981015c054d608ac5e322d896563c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=208.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07496bd875c245db820db9afc57fc498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=261.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd06db540084f9b87a8b3862905bd92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=262.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e659e2eb783447b9547c6b0da0e9c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=262.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4333eea09b054646b4ebbb3209a1c293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2cf930bb0c74f6f870e784a2a555485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6279c70b3705492fa617f806afbc7890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=71.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c9f17ad5224540a6547c01eb063d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b708e2f2affe4781875e11add3428de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8003841ebc9949deaa771eef2366e397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612d382d921b40129f6d5218f485ea16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=161.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b490a2bca44995b08d4b3d05bc4008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=162.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5b28d622394724b68cbf0ea3d3b8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=162.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02aac20f63784c3dbdba8c20e0cd45d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=208.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdb036262794dce9c495359441d474c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=261.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2cd7d99f7b4542baea9d069474824d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=262.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcee3a284ac34497b1b6465c6c873402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=262.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98657ddb986b41be84d7a358aee17fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce529dd507c1409baa44de3f69b617a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b8da32ed384df48b2767d2bbf3641a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=71.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf242c0299f4460bad5037c21415be72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0cc9ea3784a45d0abed4a1648009f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4748caddea634011b74a4e79823f4fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a877eb657a4e1bba25240f940a57c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=161.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc336398e58f4b9695a07daf11ea6b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=162.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d2f79912794c11ab64667a5830dcf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=162.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a2b9e7917445d19fb7bb00a1e28e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=208.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4c23c6cd9e437ba4acb5414b2fca91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=261.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ba17f6dfa14dea9fa8f5803ed08893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=262.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42bbe96012f4ab3bb07baf01eef95c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=262.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9078587dacca4f529f6246d320f5fc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ac6e615c7149928778561375d96f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f96ce3c9fd453db49248daeb9067ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=71.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba28179b7944f67b22dedfcbff8b2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d27b3568294c1fa1bc6902775655f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27de3c25e0a4965ba992a9c10c92cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789e21758e73481190e7c1b3ca38b3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=161.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd8b3af2fdc4cdb900f9a3e358cd483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=162.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4c761f9232479981ce9affd8f92c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=162.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caec069b3d1a4455bb0d7a814155bf76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=208.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d9c09544834f98bcb9c7921a942811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=261.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944f7e331707456980ee7e8830ce2b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=262.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f976b3129b0f43f8ad064f9fd376532e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=262.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857d4d20bae742cdb75b819907076efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d594bddb16634de8841bbe0a94b71a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c2f411248f46109ed76752088af3e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=71.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba465d4f92f24cd59bcf7aec1ff35a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c3a2490ea14b62b36e3add393a67bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30bd30cbdf144a53b03b1b92adcfb4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9774517dd5b7478db6c6850ee1bdc51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=161.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3e178b899b4715bb334b97cdd859d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=162.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e48ac08fb4447449f8a89cbc6afcddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=162.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757630a810f04ef8bfde441f1b36efc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=208.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa331e4f0340442388c5ebbe7495e222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=261.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ddbc1372114655ac6a43ff79ec3d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=262.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a08d948c6840a4889d43b0449a659b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=262.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L_scores = []\n",
    "L_XX_logit, L_XX_lgb = [], []\n",
    "# инициализируем tfidf\n",
    "for ngram_range in tqdm_notebook(tfidf_param_grid['ngram_range']):\n",
    "    for max_features in tqdm_notebook(tfidf_param_grid['max_features']):\n",
    "        \n",
    "        # получаем признаки\n",
    "        D_features = _get_tfidf_and_time_features(df_tr, df_te,\\\n",
    "                                                  target_col = 'target',\\\n",
    "                                                  vectorizer = TfidfVectorizer(ngram_range = ngram_range,\\\n",
    "                                                                               max_features = max_features)) \n",
    "        \n",
    "        # отбираем признаки бустингом\n",
    "        lgb_selector = FeatureSelector(estimator = lgb_clf,\\\n",
    "                                                   metric = 'roc_auc',\\\n",
    "                                                   larger_is_better = True,\\\n",
    "                                                   cv = tscv,\\\n",
    "                                                   use_values = D_features['to_check_values_idxs'],\\\n",
    "                                                   use_recursion = False,\\\n",
    "                                                   fill_na = FILL_NA,\\\n",
    "                                                   show_progress = False, \n",
    "                                                   early_stopping = None)            \n",
    "        lgb_selector.fit(D_features['_X_lgb_tr'][:IDX_SPLIT], D_features['_y_tr'][:IDX_SPLIT])\n",
    "\n",
    "        # auc на валидации\n",
    "        auc_lgb_cv = lgb_selector.return_self().best_score\n",
    "\n",
    "        # отобранные признаки\n",
    "        _X_lgb_sel_tr = lgb_selector.transform(D_features['_X_lgb_tr'])\n",
    "        _X_lgb_sel_te = lgb_selector.transform(D_features['_X_lgb_te'])\n",
    "\n",
    "        # auc на отложенной\n",
    "        lgb_clf.fit(_X_lgb_sel_tr[:IDX_SPLIT], D_features['_y_tr'][:IDX_SPLIT])\n",
    "        auc_lgb_hold = roc_auc_score(D_features['_y_tr'][IDX_SPLIT:],\\\n",
    "                                         lgb_clf.predict_proba(_X_lgb_sel_tr[IDX_SPLIT:])[:, 1])\n",
    "            \n",
    "        # отбираем признаки бустингом\n",
    "        logit_selector = FeatureSelector(estimator = logit_clf,\\\n",
    "                                                   metric = 'roc_auc',\\\n",
    "                                                   larger_is_better = True,\\\n",
    "                                                   cv = tscv,\\\n",
    "                                                   use_values = None,\\\n",
    "                                                   use_recursion = False,\\\n",
    "                                                   fill_na = FILL_NA,\\\n",
    "                                                   show_progress = False, \n",
    "                                                   early_stopping = None)            \n",
    "        logit_selector.fit(D_features['_X_logit_tr'][:IDX_SPLIT], D_features['_y_tr'][:IDX_SPLIT])\n",
    "\n",
    "        # auc на валидации\n",
    "        auc_logit_cv = logit_selector.return_self().best_score\n",
    "\n",
    "        # отобранные признаки\n",
    "        _X_logit_sel_tr = logit_selector.transform(D_features['_X_logit_tr'])\n",
    "        _X_logit_sel_te = logit_selector.transform(D_features['_X_logit_te'])\n",
    "\n",
    "        # auc на отложенной\n",
    "        logit_clf.fit(_X_logit_sel_tr[:IDX_SPLIT], D_features['_y_tr'][:IDX_SPLIT])\n",
    "        auc_logit_hold = roc_auc_score(D_features['_y_tr'][IDX_SPLIT:],\\\n",
    "                                           logit_clf.predict_proba(_X_logit_sel_tr[IDX_SPLIT:])[:, 1]) \n",
    "        \n",
    "        L_scores.append((ngram_range, max_features, auc_lgb_cv, auc_lgb_hold, auc_logit_cv, auc_logit_hold))\n",
    "        L_XX_logit.append((_X_logit_sel_tr, _X_logit_sel_te))\n",
    "        L_XX_lgb.append((_X_lgb_sel_tr, _X_lgb_sel_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('L_scores.pickle', 'wb') as f:\n",
    "#     pickle.dump(L_scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvAB = pd.DataFrame(L_scores, columns = ['ngram_range', 'max_features', 'lgb_cv', 'lgb_hold', 'logit_cv', 'logit_hold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = np.argmax(np.max(np.column_stack([cvAB[['lgb_cv', 'lgb_hold']].mean(1),\\\n",
    "                                                cvAB[['logit_cv', 'logit_hold']].mean(1)]), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>max_features</th>\n",
       "      <th>lgb_cv</th>\n",
       "      <th>lgb_hold</th>\n",
       "      <th>logit_cv</th>\n",
       "      <th>logit_hold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best_params</th>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>100</td>\n",
       "      <td>0.954424</td>\n",
       "      <td>0.830041</td>\n",
       "      <td>0.962221</td>\n",
       "      <td>0.95935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ngram_range max_features    lgb_cv  lgb_hold  logit_cv logit_hold\n",
       "best_params      (1, 3)          100  0.954424  0.830041  0.962221    0.95935"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvAB.iloc[best_idx].to_frame('best_params').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_features окрестность №1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L2_scores, L2_XX_logit = [], []\n",
    "# инициализируем tfidf\n",
    "for max_features in tqdm_notebook((90, 100, 110)):\n",
    "    # получаем признаки\n",
    "    D_features = _get_tfidf_and_time_features(df_tr, df_te,\\\n",
    "                                                  target_col = 'target',\\\n",
    "                                                  vectorizer = TfidfVectorizer(ngram_range = (1, 3),\\\n",
    "                                                                               max_features = max_features)) \n",
    "    # отбираем признаки бустингом\n",
    "    logit_selector = FeatureSelector(estimator = logit_clf,\\\n",
    "                                                   metric = 'roc_auc',\\\n",
    "                                                   larger_is_better = True,\\\n",
    "                                                   cv = tscv,\\\n",
    "                                                   use_values = None,\\\n",
    "                                                   use_recursion = False,\\\n",
    "                                                   fill_na = FILL_NA,\\\n",
    "                                                   show_progress = False, \n",
    "                                                   early_stopping = None)            \n",
    "    logit_selector.fit(D_features['_X_logit_tr'][:IDX_SPLIT], D_features['_y_tr'][:IDX_SPLIT])\n",
    "\n",
    "    # auc на валидации\n",
    "    auc_logit_cv = logit_selector.return_self().best_score\n",
    "\n",
    "    # отобранные признаки\n",
    "    _X_logit_sel_tr = logit_selector.transform(D_features['_X_logit_tr'])\n",
    "    _X_logit_sel_te = logit_selector.transform(D_features['_X_logit_te'])\n",
    "\n",
    "    # auc на отложенной\n",
    "    logit_clf.fit(_X_logit_sel_tr[:IDX_SPLIT], D_features['_y_tr'][:IDX_SPLIT])\n",
    "    auc_logit_hold = roc_auc_score(D_features['_y_tr'][IDX_SPLIT:],\\\n",
    "                                           logit_clf.predict_proba(_X_logit_sel_tr[IDX_SPLIT:])[:, 1]) \n",
    "    \n",
    "    L2_scores.append((max_features, auc_logit_cv, auc_logit_hold))\n",
    "    L2_XX_logit.append((_X_logit_sel_tr, _X_logit_sel_te))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores = pd.DataFrame(L2_scores).set_index(0)[[1, 2]].mean(1)\n",
    "best_score = mean_scores.max()\n",
    "best_max_features = mean_scores.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_features окрестность №2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_max_features = 90\n"
     ]
    }
   ],
   "source": [
    "low, mid, high = 89, 90, 91\n",
    "for max_features in tqdm_notebook((low, mid, high)):     \n",
    "    # получаем признаки\n",
    "    D_features = _get_tfidf_and_time_features(df_tr, df_te,\\\n",
    "                                                  target_col = 'target',\\\n",
    "                                                  vectorizer = TfidfVectorizer(ngram_range = (1, 3),\\\n",
    "                                                                               max_features = max_features)) \n",
    "    # отбираем признаки бустингом\n",
    "    logit_selector = FeatureSelector(estimator = logit_clf,\\\n",
    "                                                   metric = 'roc_auc',\\\n",
    "                                                   larger_is_better = True,\\\n",
    "                                                   cv = tscv,\\\n",
    "                                                   use_values = None,\\\n",
    "                                                   use_recursion = False,\\\n",
    "                                                   fill_na = FILL_NA,\\\n",
    "                                                   show_progress = False, \n",
    "                                                   early_stopping = None)            \n",
    "    logit_selector.fit(D_features['_X_logit_tr'][:IDX_SPLIT], D_features['_y_tr'][:IDX_SPLIT])\n",
    "\n",
    "    # auc на валидации\n",
    "    auc_logit_cv = logit_selector.return_self().best_score\n",
    "\n",
    "    # отобранные признаки\n",
    "    _X_logit_sel_tr = logit_selector.transform(D_features['_X_logit_tr'])\n",
    "    _X_logit_sel_te = logit_selector.transform(D_features['_X_logit_te'])\n",
    "\n",
    "    # auc на отложенной\n",
    "    logit_clf.fit(_X_logit_sel_tr[:IDX_SPLIT], D_features['_y_tr'][:IDX_SPLIT])\n",
    "    auc_logit_hold = roc_auc_score(D_features['_y_tr'][IDX_SPLIT:],\\\n",
    "                                           logit_clf.predict_proba(_X_logit_sel_tr[IDX_SPLIT:])[:, 1]) \n",
    "    \n",
    "    # средний auc на валидации, на отложенной выборке\n",
    "    mean_score = (auc_logit_cv+auc_logit_hold)/2\n",
    "    \n",
    "    # если улучшение\n",
    "    if mean_score>best_score:\n",
    "        best_score = mean_score\n",
    "        best_max_features = new_max_features    \n",
    "        \n",
    "if best_max_features == mid:\n",
    "    print('best_max_features = 90')\n",
    "else:\n",
    "    if best_max_features == high:\n",
    "        while True:\n",
    "            new_max_features = best_max_features+1\n",
    "            # получаем признаки\n",
    "            D_features = _get_tfidf_and_time_features(df_tr, df_te,\\\n",
    "                                                          target_col = 'target',\\\n",
    "                                                          vectorizer = TfidfVectorizer(ngram_range = (1, 3),\\\n",
    "                                                                                       max_features = new_max_features)) \n",
    "            # отбираем признаки бустингом\n",
    "            logit_selector = FeatureSelector(estimator = logit_clf,\\\n",
    "                                                           metric = 'roc_auc',\\\n",
    "                                                           larger_is_better = True,\\\n",
    "                                                           cv = tscv,\\\n",
    "                                                           use_values = None,\\\n",
    "                                                           use_recursion = False,\\\n",
    "                                                           fill_na = FILL_NA,\\\n",
    "                                                           show_progress = False, \n",
    "                                                           early_stopping = None)            \n",
    "            logit_selector.fit(D_features['_X_logit_tr'][:IDX_SPLIT], D_features['_y_tr'][:IDX_SPLIT])\n",
    "\n",
    "            # auc на валидации\n",
    "            auc_logit_cv = logit_selector.return_self().best_score\n",
    "\n",
    "            # отобранные признаки\n",
    "            _X_logit_sel_tr = logit_selector.transform(D_features['_X_logit_tr'])\n",
    "            _X_logit_sel_te = logit_selector.transform(D_features['_X_logit_te'])\n",
    "\n",
    "            # auc на отложенной\n",
    "            logit_clf.fit(_X_logit_sel_tr[:IDX_SPLIT], D_features['_y_tr'][:IDX_SPLIT])\n",
    "            auc_logit_hold = roc_auc_score(D_features['_y_tr'][IDX_SPLIT:],\\\n",
    "                                                   logit_clf.predict_proba(_X_logit_sel_tr[IDX_SPLIT:])[:, 1]) \n",
    "\n",
    "            # средний auc на валидации, на отложенной выборке\n",
    "            mean_score = (auc_logit_cv+auc_logit_hold)/2\n",
    "\n",
    "            # если улучшение\n",
    "            if mean_score>best_score:\n",
    "                best_score = mean_score\n",
    "                best_max_features = new_max_features  \n",
    "            else:\n",
    "                print('best_max_features = {}'.format(best_max_features))    \n",
    "                break\n",
    "    else:\n",
    "        while True:\n",
    "            new_max_features = best_max_features-1\n",
    "            # получаем признаки\n",
    "            D_features = _get_tfidf_and_time_features(df_tr, df_te,\\\n",
    "                                                          target_col = 'target',\\\n",
    "                                                          vectorizer = TfidfVectorizer(ngram_range = (1, 3),\\\n",
    "                                                                                       max_features = new_max_features)) \n",
    "            # отбираем признаки бустингом\n",
    "            logit_selector = FeatureSelector(estimator = logit_clf,\\\n",
    "                                                           metric = 'roc_auc',\\\n",
    "                                                           larger_is_better = True,\\\n",
    "                                                           cv = tscv,\\\n",
    "                                                           use_values = None,\\\n",
    "                                                           use_recursion = False,\\\n",
    "                                                           fill_na = FILL_NA,\\\n",
    "                                                           show_progress = False, \n",
    "                                                           early_stopping = None)            \n",
    "            logit_selector.fit(D_features['_X_logit_tr'][:IDX_SPLIT], D_features['_y_tr'][:IDX_SPLIT])\n",
    "\n",
    "            # auc на валидации\n",
    "            auc_logit_cv = logit_selector.return_self().best_score\n",
    "\n",
    "            # отобранные признаки\n",
    "            _X_logit_sel_tr = logit_selector.transform(D_features['_X_logit_tr'])\n",
    "            _X_logit_sel_te = logit_selector.transform(D_features['_X_logit_te'])\n",
    "\n",
    "            # auc на отложенной\n",
    "            logit_clf.fit(_X_logit_sel_tr[:IDX_SPLIT], D_features['_y_tr'][:IDX_SPLIT])\n",
    "            auc_logit_hold = roc_auc_score(D_features['_y_tr'][IDX_SPLIT:],\\\n",
    "                                                   logit_clf.predict_proba(_X_logit_sel_tr[IDX_SPLIT:])[:, 1]) \n",
    "\n",
    "            # средний auc на валидации, на отложенной выборке\n",
    "            mean_score = (auc_logit_cv+auc_logit_hold)/2\n",
    "\n",
    "            # если улучшение\n",
    "            if mean_score>best_score:\n",
    "                best_score = mean_score\n",
    "                best_max_features = new_max_features\n",
    "            else:\n",
    "                print('best_max_features = {}'.format(best_max_features))                \n",
    "                break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### используем весь трейн(мы выбрали модель, которая не переобучается на трейн датасет)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9703e0443c7445d194dd0c3c955bbd3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=152.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331a9d2089154a12b7780a19927ad7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=152.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best_score = 0.7996124543428651\n",
      "new best_score = 0.8092685831803784\n",
      "new best_score = 0.813276062815821\n",
      "new best_score = 0.8452663797945312\n",
      "new best_score = 0.8570511312789667\n",
      "new best_score = 0.8947537912504863\n",
      "new best_score = 0.9018019420630043\n",
      "new best_score = 0.9097443848215407\n",
      "new best_score = 0.9170488334786365\n",
      "new best_score = 0.9226383193097389\n",
      "new best_score = 0.926896101683679\n",
      "new best_score = 0.9323238559254446\n",
      "new best_score = 0.936469739825848\n",
      "new best_score = 0.941293599914627\n",
      "new best_score = 0.9466248632728534\n",
      "new best_score = 0.9474764694171118\n",
      "new best_score = 0.9479286823158859\n",
      "new best_score = 0.9481615376413506\n",
      "new best_score = 0.9487822619253508\n",
      "new best_score = 0.9495739587714154\n",
      "new best_score = 0.951906354403606\n",
      "new best_score = 0.9529583193788904\n",
      "new best_score = 0.9530077709803575\n",
      "new best_score = 0.9530412987496282\n",
      "new best_score = 0.9535215407636237\n",
      "new best_score = 0.9538852070339122\n",
      "new best_score = 0.9540997547566381\n",
      "new best_score = 0.954115113942107\n",
      "new best_score = 0.9548111488055329\n",
      "new best_score = 0.9553401983593166\n",
      "new best_score = 0.955620476000952\n",
      "new best_score = 0.9556490345219617\n",
      "new best_score = 0.9557045413593284\n",
      "new best_score = 0.9557950006739431\n",
      "new best_score = 0.9558283712343849\n",
      "new best_score = 0.9559786896597106\n",
      "new best_score = 0.9560732761907857\n",
      "new best_score = 0.9561958546069016\n",
      "new best_score = 0.9563017886666327\n",
      "new best_score = 0.9563988852443815\n",
      "new best_score = 0.9568041303556947\n",
      "new best_score = 0.9568166445084423\n",
      "new best_score = 0.9568552986106391\n",
      "new best_score = 0.9569413105966059\n",
      "new best_score = 0.9569725820339932\n",
      "new best_score = 0.957027026379947\n",
      "new best_score = 0.9572670683884039\n",
      "new best_score = 0.9573335571087287\n",
      "new best_score = 0.9573491710132186\n",
      "new best_score = 0.95736254511158\n",
      "new best_score = 0.9574282724147871\n",
      "new best_score = 0.9574609497028228\n",
      "new best_score = 0.9575450452279257\n",
      "new best_score = 0.9575545247114546\n",
      "new best_score = 0.9576051828581715\n",
      "new best_score = 0.9577472886784667\n",
      "new best_score = 0.9577920301807766\n",
      "new best_score = 0.9578004951834382\n",
      "new best_score = 0.9578455146023934\n",
      "new best_score = 0.957865157709609\n",
      "new best_score = 0.958074899468965\n",
      "new best_score = 0.9581455752916266\n",
      "new best_score = 0.9583598074876644\n",
      "new best_score = 0.9584053238978384\n",
      "new best_score = 0.9584888313126033\n",
      "new best_score = 0.958493577436116\n",
      "new best_score = 0.9584997514827519\n",
      "new best_score = 0.958544575349322\n"
     ]
    }
   ],
   "source": [
    "D_features = _get_tfidf_and_time_features(df_tr, df_te,\\\n",
    "                                          target_col = 'target',\\\n",
    "                                          vectorizer = TfidfVectorizer(ngram_range = (1, 3),\\\n",
    "                                                                       max_features = 90)) \n",
    "# отбираем признаки на всем трейне, используем рекурсию\n",
    "logit_selector = FeatureSelector(estimator = logit_clf,\\\n",
    "                                 metric = 'roc_auc',\\\n",
    "                                 larger_is_better = True,\\\n",
    "                                 cv = tscv,\\\n",
    "                                 use_values = None,\\\n",
    "                                 use_recursion = True,\\\n",
    "                                 fill_na = FILL_NA,\\\n",
    "                                 show_progress = True, \n",
    "                                 early_stopping = None)            \n",
    "logit_selector.fit(D_features['_X_logit_tr'], D_features['_y_tr'])\n",
    "_X_logit_sel_tr = logit_selector.transform(D_features['_X_logit_tr'])\n",
    "_X_logit_sel_te = logit_selector.transform(D_features['_X_logit_te'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# базовые модели\n",
    "models_L = [LogisticRegression(random_state = SEED),\\\n",
    "            Lasso(random_state = SEED),\\\n",
    "            Ridge(random_state = SEED),\\\n",
    "            DecisionTreeRegressor(random_state = SEED),\\\n",
    "            RandomForestRegressor(n_estimators = 20, random_state = SEED),\\\n",
    "            KNeighborsRegressor()]\n",
    "\n",
    "_y_tr = D_features['_y_tr']\n",
    "_X_logit_sel_tr = _X_logit_sel_tr.todense()\n",
    "_X_logit_sel_te = _X_logit_sel_te.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack1_reg = StackingEstimator(models = models_L,\\ # базовые модели                              \n",
    "                              cv = KFold(20), \\ # схемы валидации для получения метапризнаков\n",
    "                              subsample = .8,\\ # доли подпростарнств используемых признаков\n",
    "                              seed = SEED) # генератор случайных чисел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stack1_reg.fit(_X_logit_sel_tr[:IDX_SPLIT], _y_tr[:IDX_SPLIT])\n",
    "X_meta_tr = stack_reg.transform(_X_logit_sel_tr)\n",
    "X_meta_te = stack_reg.transform(_X_logit_sel_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_selector = FeatureSelector(estimator = logit_clf,\\\n",
    "                                 metric = 'roc_auc',\\\n",
    "                                 larger_is_better = True,\\\n",
    "                                 cv = tscv,\\\n",
    "                                 use_values = None,\\\n",
    "                                 use_recursion = False,\\\n",
    "                                 fill_na = FILL_NA,\\\n",
    "                                 show_progress = False, \n",
    "                                 early_stopping = None)            \n",
    "logit_selector.fit(X_meta_tr[:IDX_SPLIT], _y_tr[:IDX_SPLIT])\n",
    "_X_logit_sel_tr = logit_selector.transform(X_meta_tr)\n",
    "_X_logit_sel_te = logit_selector.transform(X_meta_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score  = logit_selector.return_self().best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вес1\n",
    "for w_logit in np.linspace(0, 1, 100):\n",
    "    \n",
    "    # вес2\n",
    "    w_lgb = 1-w_logit\n",
    "    \n",
    "    scores = []\n",
    "    for tr_idx, val_idx in tscv.split(_y_tr[:IDX_SPLIT]):\n",
    "        \n",
    "        # трейн, валидация \n",
    "        xtr, xval = _X_logit_sel_tr[tr_idx], _X_logit_sel_tr[val_idx]\n",
    "        ytr, yval = _y_tr[tr_idx], _y_tr[val_idx]\n",
    "        \n",
    "        # фитим модели\n",
    "        logit_clf.fit(xtr, ytr)\n",
    "        lgb_clf.fit(xtr, ytr)\n",
    "        \n",
    "        # делаем предсказания\n",
    "        predprob_logit = logit_clf.predict_proba(xval)[:, 1]\n",
    "        predprob_lgb = lgb_clf.predict_proba(xval)[:, 1]\n",
    "        \n",
    "        # смешиваем\n",
    "        y_blend = predprob_logit*w_logit+predprob_lgb*w_lgb\n",
    "        \n",
    "        scores.append(roc_auc_score(yval, y_blend))\n",
    "        \n",
    "    current_score = np.mean(scores)        \n",
    "    if current_score > best_score:\n",
    "        best_score = current_score\n",
    "        best_w_logit = w_logit\n",
    "        best_w_lgb = 1-best_w_logit\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('w_logit = {}, w_lgb = {}'.format(best_w_logit, best_w_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_clf.fit(_X_logit_sel_tr, _y_tr)\n",
    "lgb_clf.fit(_X_logit_sel_tr, _y_tr)\n",
    "y_predprob_logit = logit_clf.predict_proba(_X_logit_sel_te)\n",
    "y_predprob_lgb = lgb_clf.predict_proba(_X_logit_sel_te)\n",
    "\n",
    "y_blend_te = y_predprob_logit*best_w_logit + y_predprob_lgb*best_w_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
