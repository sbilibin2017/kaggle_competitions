{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import  stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csc_matrix, hstack\n",
    "from sklearn.model_selection import cross_validate, train_test_split, TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, clone\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import defaultdict\n",
    "from matplotlib_venn import venn2\n",
    "import time\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingRegressor():\n",
    "    def __init__(self, models, n_folds, seed):\n",
    "        '''\n",
    "        models - список с ансамблем моделей\n",
    "        nfolds - число фолдов для ооф предсказаний\n",
    "        seed - генератор случайных чисел\n",
    "        '''        \n",
    "        self.models = models\n",
    "        self.n_folds = n_folds  \n",
    "        self.seed=seed\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        1) обучаем модели на валидации\n",
    "        2) сохраняем обученные модели\n",
    "        ''' \n",
    "        estimators = []\n",
    "        for model in tqdm_notebook(self.models):\n",
    "            for tr_idx,val_idx in KFold(self.n_folds,random_state= self.seed).split(y):                \n",
    "                model.fit(X[tr_idx], y[tr_idx])\n",
    "                estimators.append(model)                    \n",
    "        self.fitted_estimators = estimators\n",
    "    def get_metafeatures(self, X):\n",
    "        '''\n",
    "        с помощью обученных моделей получаем метапризнаки\n",
    "        '''\n",
    "        L = []    \n",
    "        for estimator in tqdm_notebook(self.fitted_estimators):\n",
    "            L.append(estimator.predict(X))\n",
    "        return np.column_stack(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_FEATURES = r'C:\\Users\\Sergey\\anaconda3\\Scripts\\alice\\selection_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# признаки для логита, бустинга (трейн+отложенная)\n",
    "logits_tr, logits_hold, lgbs_tr, lgbs_hold =[], [], [], []\n",
    "\n",
    "for filename in os.listdir(PATH_TO_FEATURES):\n",
    "    if ('x1' in filename) & ('TR' in filename):\n",
    "        with open(os.path.join(PATH_TO_FEATURES, filename), 'rb') as f:\n",
    "            logits_tr.append(pickle.load(f))\n",
    "    elif ('x1' in filename) & ('HOLD' in filename):\n",
    "        with open(os.path.join(PATH_TO_FEATURES, filename), 'rb') as f:\n",
    "            logits_hold.append(pickle.load(f))\n",
    "    \n",
    "    elif ('x2' in filename) & ('TR' in filename):\n",
    "        with open(os.path.join(PATH_TO_FEATURES, filename), 'rb') as f:\n",
    "            lgbs_tr.append(pickle.load(f))\n",
    "    elif ('x2' in filename) & ('HOLD' in filename):\n",
    "        with open(os.path.join(PATH_TO_FEATURES, filename), 'rb') as f:\n",
    "            lgbs_hold.append(pickle.load(f))\n",
    "            \n",
    "with open('target_TR', 'rb') as f:\n",
    "    _y_TR = pickle.load(f)\n",
    "    \n",
    "with open('target_HOLD', 'rb') as f:\n",
    "    _y_HOLD = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генератор случайных чисел\n",
    "SEED=13\n",
    "\n",
    "# базовые модели\n",
    "BASE_MODELS_LINEAR = [Lasso(random_state = SEED),\\\n",
    "                      Ridge(random_state = SEED),\n",
    "                      KNeighborsRegressor(),\\\n",
    "                      LinearSVR(random_state = SEED)]\n",
    "BASE_MODELS_TREE = [RandomForestRegressor(random_state = SEED),\\\n",
    "                    LGBMRegressor(random_state = SEED),\\\n",
    "                    XGBRegressor(random_state = SEED),\\\n",
    "                    KNeighborsRegressor(),\\\n",
    "                    DecisionTreeRegressor(random_state = SEED)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "число датасетов равно 12\n"
     ]
    }
   ],
   "source": [
    "print('число датасетов равно {}'.format(len(logits_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# гиперпараметры стекинга\n",
    "N_FOLDS_STACKING = 5 # число фолдов в стекинге\n",
    "N_ITERATIONS = 5 # число итераций стекинга\n",
    "N_SUBSAMPLES = 5 # число итераций обучения базовых моделей\n",
    "uniform_LOW, uniform_HIGH = .5, 1 # параметры распределения доли используемых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107186f2cdae4851a443cfd91a8f0171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5dde80a08b49f28b334416da240c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a5389a9f88416e8c824dbd4a64f5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7318f3a9e0fe4755ba54bad107f029c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a570cc1c3b641309749d76758801ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# стекинг линейных моделей\n",
    "_logit_TRs, _logit_HOLDs = [], []\n",
    "\n",
    "# делаем стекинг N_ITERATIONS раз\n",
    "for seed1 in tqdm_notebook(range(1, N_ITERATIONS+1)):\n",
    "    \n",
    "    # фиксируем валидационную схему для получения ооф предсказаний\n",
    "    stacking_reg_linear = StackingRegressor(models = BASE_MODELS_LINEAR, n_folds=N_FOLDS_STACKING, seed = SEED+seed1)\n",
    "\n",
    "    # списки с метапризнаками\n",
    "    L_metas_TR, L_metas_HOLD = [], []\n",
    "    \n",
    "    # отобранные признаки для фолдов от 3 до 6\n",
    "    for features_tr, features_hold in tqdm_notebook(zip(logits_tr, logits_hold), total = len(logits_tr)):\n",
    "        \n",
    "        # делаем подвыборки признаков N_SUBSAMPLES раз\n",
    "        for seed2 in tqdm_notebook(range(1, N_SUBSAMPLES+1)):\n",
    "\n",
    "            # генератор случайных чисел\n",
    "            np.random.seed(SEED+seed1+seed2)\n",
    "\n",
    "            # всего признаков\n",
    "            nfeat_total = features_tr.shape[1]\n",
    "            # доля используемых признаков (равномерная от .5 до 1)\n",
    "            feat_share = np.random.uniform(uniform_LOW, uniform_HIGH)\n",
    "            # число используемых признаков\n",
    "            nfeat_to_select = np.int32(np.around(feat_share*nfeat_total))\n",
    "            # индексы используемых признаков\n",
    "            feat_idxs_subset = np.random.choice(np.arange(nfeat_total), nfeat_to_select, replace = False)\n",
    "\n",
    "            # метапризнаки\n",
    "            stacking_reg_linear.fit(features_tr[:, feat_idxs_subset], _y_TR)\n",
    "            L_metas_TR.append(stacking_reg_linear.get_metafeatures(features_tr[:, feat_idxs_subset]))\n",
    "            L_metas_HOLD.append(stacking_reg_linear.get_metafeatures(features_hold[:, feat_idxs_subset]))\n",
    "            print('ok')\n",
    "            \n",
    "    _logit_TRs.append(L_metas_TR)\n",
    "    _logit_HOLDs.append(L_metas_HOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# стекинг деревьев\n",
    "_lgb_TRs, _lgb_HOLDs = [], []\n",
    "\n",
    "# делаем стекинг N_ITERATIONS раз\n",
    "for seed1 in tqdm_notebook(range(1, N_ITERATIONS+1)):\n",
    "    \n",
    "    # фиксируем валидационную схему для получения ооф предсказаний\n",
    "    stacking_reg_tree= StackingRegressor(models = BASE_MODELS_TREE, n_folds=N_FOLDS_STACKING, seed = SEED+seed1)\n",
    "\n",
    "    # списки с метапризнаками\n",
    "    L_metas_TR, L_metas_HOLD = [], []\n",
    "    \n",
    "    # отобранные признаки для фолдов от 3 до 6\n",
    "    for features_tr, features_hold in tqdm_notebook(zip(lgbs_tr, lgbs_hold), total = len(lgbs_tr)):\n",
    "        \n",
    "        # делаем подвыборки признаков N_SUBSAMPLES раз\n",
    "        for seed2 in tqdm_notebook(range(1, N_SUBSAMPLES+1)):\n",
    "\n",
    "            # генератор случайных чисел\n",
    "            np.random.seed(SEED+seed1+seed2)\n",
    "\n",
    "            # всего признаков\n",
    "            nfeat_total = features_tr.shape[1]\n",
    "            # доля используемых признаков (равномерная от .5 до 1)\n",
    "            feat_share = np.random.uniform(uniform_LOW, uniform_HIGH)\n",
    "            # число используемых признаков\n",
    "            nfeat_to_select = np.int32(np.around(feat_share*nfeat_total))\n",
    "            # индексы используемых признаков\n",
    "            feat_idxs_subset = np.random.choice(np.arange(nfeat_total), nfeat_to_select, replace = False)\n",
    "\n",
    "            # метапризнаки\n",
    "            stacking_reg_tree.fit(features_tr[:, feat_idxs_subset], _y_TR)\n",
    "            L_metas_TR.append(stacking_reg_tree.get_metafeatures(features_tr[:, feat_idxs_subset]))\n",
    "            L_metas_HOLD.append(stacking_reg_tree.get_metafeatures(features_hold[:, feat_idxs_subset]))\n",
    "            \n",
    "    _lgb_TRs.append(L_metas_TR)\n",
    "    _lgb_HOLDs.append(L_metas_HOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
