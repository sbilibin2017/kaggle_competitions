{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import  stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csc_matrix, hstack\n",
    "from sklearn.model_selection import cross_validate, train_test_split, TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, clone\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import defaultdict\n",
    "from matplotlib_venn import venn2\n",
    "import time\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector():\n",
    "    def __init__(self, estimator,\n",
    "                       metric,\\\n",
    "                       larger_is_better,\\\n",
    "                       cv,\n",
    "                       use_values,\\\n",
    "                       use_recursion,\n",
    "                       fill_na,\\\n",
    "                       show_progress, \n",
    "                       early_stopping = None):\n",
    "        '''\n",
    "        Инициализирует модель для отбора признаков\n",
    "        \n",
    "        Параметры:\n",
    "            1) estimator - модель\n",
    "            2) metric - метрика качества (названия метрик sklearn + может быть кастомная)\n",
    "            3) larger_is_better - критерий оптимизации (чем больше, тем лучше)\n",
    "            4) cv - схема валидации\n",
    "            5) use_values - индексы столбцов, в которых требуется отобрать значения\n",
    "            6) use_recursion - использовать рекурсию в отборе\n",
    "            7) fill_na - значение, которым заполняются np.nan\n",
    "            8) show_progress - печатать результаты валидации\n",
    "            9) early_stopping - число итераций без улучшения метрики для ранней остановки отбора\n",
    "        Возвращает:\n",
    "            1) fit - производит отбор признаков\n",
    "            2) transform - оставляет отобранные признаки\n",
    "            3) return_self - возвращает \n",
    "                - best_features - отобранные признаки(список)\n",
    "                - D_best_features - отобранные значения признаков (словарь: {признак:значения})\n",
    "                - best_score - лучшее значение метрики\n",
    "        '''\n",
    "        self.estimator = estimator\n",
    "        self.metric = metric\n",
    "        self.cv = cv\n",
    "        self.use_values = use_values        \n",
    "        self.use_recursion = use_recursion\n",
    "        self.show_progress = show_progress\n",
    "        self.early_stopping = early_stopping\n",
    "        self.fill_na = fill_na\n",
    "        self.larger_is_better = larger_is_better\n",
    "    def fit(self, X, Y):        \n",
    "        flag = isinstance(X[:, 0], csc_matrix)\n",
    "        # список с результатами валидации\n",
    "        column_value_score = []\n",
    "        # проходим по признакам\n",
    "        for i in tqdm_notebook(range(X.shape[1])):\n",
    "            # если формат матрицы признаков == csc_matrix\n",
    "            if flag:\n",
    "                # выбираем столбец, преобразуем\n",
    "                ser = pd.DataFrame(X[:, i].todense())[0].values.flatten()\n",
    "            # если формат != csc_matrix\n",
    "            else:\n",
    "                # выбираем столбец\n",
    "                ser = X[:, i]        \n",
    "            # если столбец в списке с проверкой значений \n",
    "            if self.use_values is not None:                \n",
    "                if i in self.use_values:\n",
    "                    # уникальные значения столбца\n",
    "                    unique_values = np.unique(ser)  \n",
    "                    # валидируем каждое значение\n",
    "                    for val in unique_values:\n",
    "                        _x = np.int32(ser==val).reshape(-1,1)\n",
    "                        column_value_score.append((i, val,\\\n",
    "                                                   cross_val_score(self.estimator,\\\n",
    "                                                                   _x, Y,\\\n",
    "                                                                   scoring = self.metric,\\\n",
    "                                                                   cv = self.cv).mean()))\n",
    "                else: \n",
    "                    # валидируем столбец\n",
    "                    column_value_score.append((i, None,\\\n",
    "                                               cross_val_score(self.estimator,\\\n",
    "                                                               _x, Y,\\\n",
    "                                                               scoring = self.metric,\\\n",
    "                                                               cv = self.cv).mean()))\n",
    "            else:\n",
    "                # валидируем столбец\n",
    "                    column_value_score.append((i, None,\\\n",
    "                                               cross_val_score(self.estimator,\\\n",
    "                                                               ser.reshape(-1,1), Y,\\\n",
    "                                                               scoring = self.metric,\\\n",
    "                                                               cv = self.cv).mean()))\n",
    "                \n",
    "\n",
    "        # признаки и значения признаков в порядке убывания валидации\n",
    "        order = np.array(sorted(column_value_score, key = lambda x: x[-1], reverse = True))[:, :2]             \n",
    "        # список лучших признаков\n",
    "        best_features = []\n",
    "        # словарь лучших значений признаков\n",
    "        D_best_features = defaultdict(list)\n",
    "        # список с признаками, не давшими прироста\n",
    "        to_drop = []\n",
    "        \n",
    "        # лучшее значение метрики\n",
    "        if self.larger_is_better:\n",
    "            best_score = 0\n",
    "        else:\n",
    "            best_score = np.inf            \n",
    "        counter = 0\n",
    "        # проходим по признакам и значениям признаков в порядке убывания валидации\n",
    "        for feature, feature_value in tqdm_notebook(order):   \n",
    "\n",
    "            # добавляем текущие признаки/значения\n",
    "            if feature_value is None:\n",
    "                best_features.append(feature)               \n",
    "            else:\n",
    "                D_best_features[feature].append(feature_value)\n",
    "\n",
    "            # обновляем матрицы\n",
    "            L = []\n",
    "            for k, v in D_best_features.items():\n",
    "                if isinstance(X[:, k], csc_matrix):\n",
    "                    L.append(pd.DataFrame(X[:, k].tocsc().todense())[0].apply(lambda x: x if x in v else self.fill_na))\n",
    "                else:\n",
    "                    L.append(pd.Series(X[:, k].flatten()).apply(lambda x: x if x in v else self.fill_na))\n",
    "\n",
    "            if flag:\n",
    "                if (len(best_features)>0) & (len(L)>0):\n",
    "                    _X = csc_matrix(hstack([X[:, best_features], csc_matrix(np.column_stack(L)) ]))\n",
    "                elif (len(best_features)==0) & (len(L)>0):\n",
    "                    _X = csc_matrix(np.column_stack(L))\n",
    "                elif (len(best_features)>0) & (len(L)==0):\n",
    "                    _X = csc_matrix(X[:, best_features])                    \n",
    "                        \n",
    "            else:\n",
    "                if (len(best_features)>0) & (len(L)>0):\n",
    "                    _X = np.column_stack([X[:, best_features], np.column_stack(L)])\n",
    "                elif (len(best_features)==0) & (len(L)>0):\n",
    "                    _X = np.column_stack(L)\n",
    "                elif (len(best_features)>0) & (len(L)==0):\n",
    "                    _X = X[:, best_features] \n",
    "            # считаем валидацию    \n",
    "            current_score = cross_val_score(self.estimator, _X, Y, scoring = self.metric, cv = self.cv).mean()\n",
    "            # если метрика улучшилась\n",
    "            if self.larger_is_better:\n",
    "                if current_score>best_score:\n",
    "                    # обновляем лучшую метрику\n",
    "                    best_score = current_score\n",
    "                    counter = 0\n",
    "                    # печатаем \n",
    "                    if self.show_progress:\n",
    "                        print('new best_score = {}'.format(best_score))\n",
    "                # если метрика не улучшилась\n",
    "                else: \n",
    "                    counter+=1\n",
    "                    # удаляем признак/значение\n",
    "                    if feature_value is None:\n",
    "                        best_features = [val for val in best_features if val != feature]\n",
    "                        to_drop.append((feature, None))\n",
    "                    else:\n",
    "                        D_best_features[feature] = [val for val in D_best_features[feature] if val != feature_value]    \n",
    "                        to_drop.append((feature, feature_value))\n",
    "                    if counter == self.early_stopping:\n",
    "                        break\n",
    "            else:\n",
    "                if current_score<best_score:\n",
    "                    # обновляем лучшую метрику\n",
    "                    best_score = current_score\n",
    "                    counter = 0\n",
    "                    # печатаем \n",
    "                    if self.show_progress:\n",
    "                        print('new best_score = {}'.format(best_score))\n",
    "                    # если метрика не улучшилась\n",
    "                else: \n",
    "                    counter+=1\n",
    "                    # удаляем признак/значение\n",
    "                    if feature_value is None:\n",
    "                        best_features = [val for val in best_features if val != feature]\n",
    "                        to_drop.append((feature, None))\n",
    "                    else:\n",
    "                        D_best_features[feature] = [val for val in D_best_features[feature] if val != feature_value]    \n",
    "                        to_drop.append((feature, feature_value))\n",
    "                    if counter == self.early_stopping:\n",
    "                        break\n",
    "\n",
    "        if self.use_recursion:\n",
    "            # запускаем бесконечный цикл\n",
    "            while True:\n",
    "                # списки лучших признаков до и после\n",
    "                to_drop_before = to_drop\n",
    "                to_drop_after = []\n",
    "                # проходим по признакам и значениям признаков в порядке убывания валидации\n",
    "                for feature, feature_value in tqdm_notebook(to_drop_before):   \n",
    "                    # добавляем текущие признаки/значения\n",
    "                    if feature_value is None:\n",
    "                        best_features.append(feature)               \n",
    "                    else:\n",
    "                        D_best_features[feature].append(feature_value)\n",
    "\n",
    "                    # обновляем матрицы\n",
    "                    L = []\n",
    "                    for k, v in D_best_features.items():\n",
    "                        if isinstance(X[:, k], csc_matrix):\n",
    "                            L.append(pd.DataFrame(X[:, k].tocsc().todense())[0].apply(lambda x: x if x in v else self.fill_na))\n",
    "                        else:\n",
    "                            L.append(pd.Series(X[:, k].flatten()).apply(lambda x: x if x in v else self.fill_na))\n",
    "\n",
    "                    if flag:\n",
    "                        if (len(best_features)>0) & (len(L)>0):\n",
    "                            _X = csc_matrix(hstack([X[:, best_features], csc_matrix(np.column_stack(L)) ]))\n",
    "                        elif (len(best_features)==0) & (len(L)>0):\n",
    "                            _X = csc_matrix(np.column_stack(L))\n",
    "                        elif (len(best_features)>0) & (len(L)==0):\n",
    "                            _X = csc_matrix(X[:, best_features])                    \n",
    "\n",
    "                    else:\n",
    "                        if (len(best_features)>0) & (len(L)>0):\n",
    "                            _X = np.column_stack([X[:, best_features], np.column_stack(L)])\n",
    "                        elif (len(best_features)==0) & (len(L)>0):\n",
    "                            _X = np.column_stack(L)\n",
    "                        elif (len(best_features)>0) & (len(L)==0):\n",
    "                            _X = X[:, best_features] \n",
    "\n",
    "                    # считаем валидацию    \n",
    "                    current_score = cross_val_score(self.estimator, _X, Y, scoring = self.metric, cv = self.cv).mean()\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    if self.larger_is_better:\n",
    "                        if current_score>best_score:\n",
    "                            # обновляем лучшую метрику\n",
    "                            best_score = current_score\n",
    "                            counter = 0\n",
    "                            # печатаем \n",
    "                            if self.show_progress:\n",
    "                                print('new best_score = {}'.format(best_score))\n",
    "                            # если метрика не улучшилась\n",
    "                        else: \n",
    "                            # удаляем признак/значение\n",
    "                            if feature_value is None:\n",
    "                                best_features = [val for val in best_features if val != feature]\n",
    "                                to_drop_after.append((feature, None))\n",
    "                            else:\n",
    "                                D_best_features[feature] = [val for val in D_best_features[feature] if val != feature_value]    \n",
    "                                to_drop_after.append((feature, feature_value))\n",
    "                    else:\n",
    "                        if current_score<best_score:\n",
    "                            # обновляем лучшую метрику\n",
    "                            best_score = current_score\n",
    "                            counter = 0\n",
    "                            # печатаем \n",
    "                            if self.show_progress:\n",
    "                                print('new best_score = {}'.format(best_score))\n",
    "                        else: \n",
    "                            # удаляем признак/значение\n",
    "                            if feature_value is None:\n",
    "                                best_features = [val for val in best_features if val != feature]\n",
    "                                to_drop_after.append((feature, None))\n",
    "                            else:\n",
    "                                D_best_features[feature] = [val for val in D_best_features[feature] if val != feature_value]    \n",
    "                                to_drop_after.append((feature, feature_value))\n",
    "                    \n",
    "\n",
    "                # если списки одинаковые, останавливаем отбор\n",
    "                if len(to_drop_after) == len(to_drop_before):\n",
    "                    break\n",
    "                # если разные - обновляем списки до и после\n",
    "                else:\n",
    "                    to_drop_before = to_drop_after\n",
    "                    to_drop_after = []\n",
    "                    \n",
    "        self.best_features = best_features\n",
    "        self.D_best_features = D_best_features\n",
    "        self.best_score =best_score\n",
    "        self.flag = flag\n",
    "    def transform(self, X):\n",
    "              \n",
    "        if len(self.best_features) !=0:\n",
    "            x1 = X[:, self.best_features]\n",
    "        else:\n",
    "            x1 = None\n",
    "        if len(list(self.D_best_features.keys())) !=0:\n",
    "            L=[]\n",
    "            for k, v in self.D_best_features.items():\n",
    "                if self.flag:\n",
    "                    L.append(pd.DataFrame(X[:, k].tocsc().todense())[0].apply(lambda x: x if x in v else self.fill_na))                    \n",
    "                else:\n",
    "                    L.append(pd.Series(X[:, k].flatten()).apply(lambda x: x if x in v else self.fill_na))\n",
    "            x2 = np.column_stack(L)\n",
    "        else:\n",
    "            x2 = None\n",
    "            \n",
    "        if (x1 is not None) & (x2 is not None):\n",
    "            if self.flag: \n",
    "                _X = csc_matrix(hstack([x1, x2]))\n",
    "            else:\n",
    "                _X = np.column_stack([x1, x2])\n",
    "                \n",
    "        if (x1 is not None) & (x2 is None):\n",
    "            _X = x1\n",
    "        if (x1 is None) & (x2 is not None):\n",
    "            if self.flag:\n",
    "                _X = csc_matrix(x2)\n",
    "            else:\n",
    "                _X = x2\n",
    "        return _X     \n",
    "        \n",
    "    def return_self(self):\n",
    "        return self\n",
    "\n",
    "\n",
    "class StackingRegressor():\n",
    "    def __init__(self, models, n_folds, seed):\n",
    "        '''\n",
    "        models - список с ансамблем моделей\n",
    "        nfolds - число фолдов для ооф предсказаний\n",
    "        seed - генератор случайных чисел\n",
    "        '''        \n",
    "        self.models = models\n",
    "        self.n_folds = n_folds  \n",
    "        self.seed=seed\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        1) обучаем модели на валидации\n",
    "        2) сохраняем обученные модели\n",
    "        ''' \n",
    "        estimators = []\n",
    "        for model in tqdm_notebook(self.models):\n",
    "            for tr_idx,val_idx in KFold(self.n_folds,random_state= self.seed).split(y):                \n",
    "                model.fit(X[tr_idx], y[tr_idx])\n",
    "                estimators.append(model)                    \n",
    "        self.fitted_estimators = estimators\n",
    "    def get_metafeatures(self, X):\n",
    "        '''\n",
    "        с помощью обученных моделей получаем метапризнаки\n",
    "        '''\n",
    "        L = []    \n",
    "        for estimator in tqdm_notebook(self.fitted_estimators):\n",
    "            L.append(estimator.predict(X))\n",
    "        return np.column_stack(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_FEATURES = r'C:\\Users\\Sergey\\anaconda3\\Scripts\\alice\\selection_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# признаки для логита, бустинга (трейн+отложенная)\n",
    "logits_tr, logits_hold, lgbs_tr, lgbs_hold =[], [], [], []\n",
    "\n",
    "for filename in os.listdir(PATH_TO_FEATURES):\n",
    "    if ('x1' in filename) & ('TR' in filename):\n",
    "        with open(os.path.join(PATH_TO_FEATURES, filename), 'rb') as f:\n",
    "            logits_tr.append(pickle.load(f))\n",
    "    elif ('x1' in filename) & ('HOLD' in filename):\n",
    "        with open(os.path.join(PATH_TO_FEATURES, filename), 'rb') as f:\n",
    "            logits_hold.append(pickle.load(f))\n",
    "    \n",
    "    elif ('x2' in filename) & ('TR' in filename):\n",
    "        with open(os.path.join(PATH_TO_FEATURES, filename), 'rb') as f:\n",
    "            lgbs_tr.append(pickle.load(f))\n",
    "    elif ('x2' in filename) & ('HOLD' in filename):\n",
    "        with open(os.path.join(PATH_TO_FEATURES, filename), 'rb') as f:\n",
    "            lgbs_hold.append(pickle.load(f))\n",
    "            \n",
    "with open('target_TR', 'rb') as f:\n",
    "    _y_TR = pickle.load(f)\n",
    "    \n",
    "with open('target_HOLD', 'rb') as f:\n",
    "    _y_HOLD = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генератор случайных чисел\n",
    "SEED=13\n",
    "\n",
    "# базовые модели\n",
    "BASE_MODELS_LINEAR = [Lasso(random_state = SEED),\\\n",
    "                      Ridge(random_state = SEED),\n",
    "                      KNeighborsRegressor(),\\\n",
    "                      LinearSVR(random_state = SEED)]\n",
    "BASE_MODELS_TREE = [RandomForestRegressor(random_state = SEED),\\\n",
    "                    LGBMRegressor(random_state = SEED),\\\n",
    "                    XGBRegressor(random_state = SEED),\\\n",
    "                    KNeighborsRegressor(),\\\n",
    "                    DecisionTreeRegressor(random_state = SEED)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "число датасетов равно 12\n"
     ]
    }
   ],
   "source": [
    "print('число датасетов равно {}'.format(len(logits_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# гиперпараметры стекинга\n",
    "N_FOLDS_STACKING = 5 # число фолдов в стекинге\n",
    "N_ITERATIONS = 5 # число итераций стекинга\n",
    "N_SUBSAMPLES = 5 # число итераций обучения базовых моделей\n",
    "uniform_LOW, uniform_HIGH = .5, 1 # параметры распределения доли используемых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6f26fd24ef40d0968f481bbd0be8b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698559095b71474aa438a62c6e83d6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175b1744b97a478fad2c749fc697f53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54e54b538cf486094997d81c3631fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# стекинг линейных моделей\n",
    "_logit_TRs, _logit_HOLDs = [], []\n",
    "\n",
    "# делаем стекинг N_ITERATIONS раз\n",
    "for seed1 in tqdm_notebook(range(1, N_ITERATIONS+1)):\n",
    "    \n",
    "    # фиксируем валидационную схему для получения ооф предсказаний\n",
    "    stacking_reg_linear = StackingRegressor(models = BASE_MODELS_LINEAR, n_folds=N_FOLDS_STACKING, seed = SEED+seed1)\n",
    "\n",
    "    # списки с метапризнаками\n",
    "    L_metas_TR, L_metas_HOLD = [], []\n",
    "    \n",
    "    # отобранные признаки для фолдов от 3 до 6\n",
    "    for features_tr, features_hold in tqdm_notebook(zip(logits_tr, logits_hold), total = len(logits_tr)):\n",
    "        \n",
    "        # делаем подвыборки признаков N_SUBSAMPLES раз\n",
    "        for seed2 in tqdm_notebook(range(1, N_SUBSAMPLES+1)):\n",
    "\n",
    "            # генератор случайных чисел\n",
    "            np.random.seed(SEED+seed1+seed2)\n",
    "\n",
    "            # всего признаков\n",
    "            nfeat_total = features_tr.shape[1]\n",
    "            # доля используемых признаков (равномерная от .5 до 1)\n",
    "            feat_share = np.random.uniform(uniform_LOW, uniform_HIGH)\n",
    "            # число используемых признаков\n",
    "            nfeat_to_select = np.int32(np.around(feat_share*nfeat_total))\n",
    "            # индексы используемых признаков\n",
    "            feat_idxs_subset = np.random.choice(np.arange(nfeat_total), nfeat_to_select, replace = False)\n",
    "            \n",
    "            __X_tr = np.array(features_tr.todense())\n",
    "            __X_hold = np.array(features_hold.todense())\n",
    "            # метапризнаки\n",
    "            stacking_reg_linear.fit(__X_tr[:, feat_idxs_subset], _y_TR)\n",
    "            L_metas_TR.append(stacking_reg_linear.get_metafeatures(__X_tr[:, feat_idxs_subset]))\n",
    "            L_metas_HOLD.append(stacking_reg_linear.get_metafeatures(__X_hold[:, feat_idxs_subset]))\n",
    "            \n",
    "    _logit_TRs.append(L_metas_TR)\n",
    "    _logit_HOLDs.append(L_metas_HOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# стекинг деревьев\n",
    "_lgb_TRs, _lgb_HOLDs = [], []\n",
    "\n",
    "# делаем стекинг N_ITERATIONS раз\n",
    "for seed1 in tqdm_notebook(range(1, N_ITERATIONS+1)):\n",
    "    \n",
    "    # фиксируем валидационную схему для получения ооф предсказаний\n",
    "    stacking_reg_tree= StackingRegressor(models = BASE_MODELS_TREE, n_folds=N_FOLDS_STACKING, seed = SEED+seed1)\n",
    "\n",
    "    # списки с метапризнаками\n",
    "    L_metas_TR, L_metas_HOLD = [], []\n",
    "    \n",
    "    # отобранные признаки для фолдов от 3 до 6\n",
    "    for features_tr, features_hold in tqdm_notebook(zip(lgbs_tr, lgbs_hold), total = len(lgbs_tr)):\n",
    "        \n",
    "        # генератор случайных чисел\n",
    "            np.random.seed(SEED+seed1+seed2)\n",
    "\n",
    "            # всего признаков\n",
    "            nfeat_total = features_tr.shape[1]\n",
    "            # доля используемых признаков (равномерная от .5 до 1)\n",
    "            feat_share = np.random.uniform(uniform_LOW, uniform_HIGH)\n",
    "            # число используемых признаков\n",
    "            nfeat_to_select = np.int32(np.around(feat_share*nfeat_total))\n",
    "            # индексы используемых признаков\n",
    "            feat_idxs_subset = np.random.choice(np.arange(nfeat_total), nfeat_to_select, replace = False)\n",
    "            \n",
    "            __X_tr = np.array(features_tr.todense())\n",
    "            __X_hold = np.array(features_hold.todense())\n",
    "            # метапризнаки\n",
    "            stacking_reg_tree.fit(__X_tr[:, feat_idxs_subset], _y_TR)\n",
    "            L_metas_TR.append(stacking_reg_tree.get_metafeatures(__X_tr[:, feat_idxs_subset]))\n",
    "            L_metas_HOLD.append(stacking_reg_tree.get_metafeatures(__X_hold[:, feat_idxs_subset]))\n",
    "            \n",
    "    _lgb_TRs.append(L_metas_TR)\n",
    "    _lgb_HOLDs.append(L_metas_HOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_TR, X2_tr, X1_HOLD, X2_HOLD = np.column_stack(_logit_TRs), np.column_stack(_lgb_TRs),\\\n",
    "                                 np.column_stack(_logit_HOLDs), np.column_stack(_lgb_HOLDs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем взаимодействия пар признаков\n",
    "\n",
    "interactions1_TR, interactions1_HOLD = [], []\n",
    "for i in range(X1_TR.shape[1]):\n",
    "    for j in range(i+1,X1_TR.shape[1]):\n",
    "        _x1tr, _x2tr = X1_TR[:, i], X1_TR[:, j]\n",
    "        interactions1_TR.append((_x1tr+_x2tr) / 2)\n",
    "        interactions1_TR.append(np.sqrt(_x1tr*_x2tr))\n",
    "        \n",
    "        _x1hold, _x2hold = X1_HOLD[:, i], X1_HOLD[:, j]\n",
    "        interactions1_HOLD.append((_x1hold+_x2hold) / 2)\n",
    "        interactions1_HOLD.append(np.sqrt(_x1hold*_x2hold))\n",
    "        \n",
    "interactions2_TR, interactions2_HOLD = [], []\n",
    "for i in range(X2_TR.shape[1]):\n",
    "    for j in range(i+1,X2_TR.shape[1]):\n",
    "        _x1tr, _x2tr = X2_TR[:, i], X2_TR[:, j]\n",
    "        interactions2_TR.append((_x1tr+_x2tr) / 2)\n",
    "        interactions2_TR.append(np.sqrt(_x1tr*_x2tr))\n",
    "        \n",
    "        _x1hold, _x2hold = X2_HOLD[:, i], X2_HOLD[:, j]\n",
    "        interactions2_HOLD.append((_x1hold+_x2hold) / 2)\n",
    "        interactions2_HOLD.append(np.sqrt(_x1hold*_x2hold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_final_TR, X2_final_tr, X1_final_HOLD, X2_final_HOLD =\\\n",
    "    np.column_stack(interactions1_TR), np.column_stack(interactions2_TR),\\\n",
    "    np.column_stack(interactions1_HOLD), np.column_stack(interactions2_HOLD)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_selector = FeatureSelector(estimator = LGBMRegressor(random_state = SEED),\\\n",
    "                                               metric = 'roc_auc',\\\n",
    "                                               larger_is_better = True,\\\n",
    "                                               cv = tscv,\\\n",
    "                                               use_values = None,\\\n",
    "                                               use_recursion = False,\\\n",
    "                                               fill_na = FILL_NA,\\\n",
    "                                               show_progress = False)\n",
    "knn_selector = FeatureSelector(estimator = KNeighborsRegressor(),\\\n",
    "                                               metric = 'roc_auc',\\\n",
    "                                               larger_is_better = True,\\\n",
    "                                               cv = tscv,\\\n",
    "                                               use_values = None,\\\n",
    "                                               use_recursion = False,\\\n",
    "                                               fill_na = FILL_NA,\\\n",
    "                                               show_progress = False)\n",
    "lasso_selector = FeatureSelector(estimator = Lasso(random_State =SEED),\\\n",
    "                                                 metric = 'roc_auc',\\\n",
    "                                                 larger_is_better = True,\\\n",
    "                                                 cv = tscv,\\\n",
    "                                                 use_values = None,\\\n",
    "                                                 use_recursion = False,\\\n",
    "                                                 fill_na = FILL_NA,\\\n",
    "                                                 show_progress = False)\n",
    "\n",
    "ridge_selector = FeatureSelector(estimator = Ridge(random_State =SEED),\\\n",
    "                                                 metric = 'roc_auc',\\\n",
    "                                                 larger_is_better = True,\\\n",
    "                                                 cv = tscv,\\\n",
    "                                                 use_values = None,\\\n",
    "                                                 use_recursion = False,\\\n",
    "                                                 fill_na = FILL_NA,\\\n",
    "                                                 show_progress = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_selector.fit(X1_final_TR, _y_TR)\n",
    "X_lgb = np.row_stack([lgb_selector.transform(X1_final_TR),\\\n",
    "              lgb_selector.transform(X1_final_TE)])\n",
    "lgb_best_score = lgb_selector.return_self().best_score\n",
    "\n",
    "knn_selector.fit(X1_final_TR, _y_TR)\n",
    "knn_best_score = knn_selector.return_self().best_score\n",
    "X_knn = np.row_stack([knn_selector.transform(X1_final_TR)\n",
    "                      knn_selector.transform(X1_final_TE)])\n",
    "    \n",
    "    \n",
    "lasso_selector.fit(X1_final_TR, _y_TR)\n",
    "\n",
    "lasso_best_score = lasso_selector.return_self().best_score\n",
    "X_lasso = np.row_stack([lasso_selector.transform(X1_final_TR)\n",
    "                        lasso_selector.transform(X1_final_TE)])\n",
    "\n",
    "\n",
    "ridge_selector.fit(X1_final_TR, _y_TR)\n",
    "ridge_best_score = ridge_selector.return_self().best_score\n",
    "\n",
    "X_ridge = np.row_stack([ridge_selector.transform(X1_final_TR)\n",
    "                          ridge_selector.transform(X1_final_TE)])\n",
    "\n",
    "scores = pd.Series([lgb_best_score, knn_best_score, lasso_best_score, ridge_best_score])\n",
    "weights = (scores / scores.sum()).values.flatten()\n",
    "Xs = (X_lgb, X_knn, X_lasso, X_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1, L2 = [], []\n",
    "for Xtr, Xte, weight in zip(Xstr,Xste, weights):\n",
    "    L1.append(logit_clf.fit(Xtr, _y_tr).predict_proba(Xte)[:, 1].flatten()*weights)\n",
    "    L2.append(lgb_clf.fit(Xtr, _y_tr).predict_proba(Xte)[:, 1].flatten()*weights)\n",
    "    \n",
    "final_blend = np.sum(L1, 1)*.7 + .3 *np.sum(L2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
